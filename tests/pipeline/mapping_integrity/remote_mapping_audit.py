"""
BDC Remote Logic Auditor (v2.0.0).

=============================================================================
Project: NHLBI BioData Catalyst (BDC) Data Management Center (DMC)
Phase:   Phase 0.5 - Remote Mapping Validation

PURPOSE:
Validates HV transformation YAMLs hosted on GitHub against a local
Master Manifest (CSV).

KEY FEATURES:
1. GitHub Integration: Fetches specification files directly via URL.
2. Manifest Authority: Uses the provided CSV as the "Source of Truth."
3. Version Agnostic: Cleans versioning (e.g., .v1.p1) for reliable matching.
=============================================================================
"""

import os
import re

import pandas as pd
import requests
import yaml

# =============================================================================
# 1. CONFIGURATION
# =============================================================================

# Mapping of cohort names (as they appear in CSV) to their GitHub transform directories
COHORT_CONFIGS = {
    "Atherosclerosis Risk in Communities (ARIC) Cohort":
        "https://github.com/RTIInternational/NHLBI-BDC-DMC-HV/tree/main/priority_variables_transform/ARIC-ingest",

    "CARDIA Cohort":
        "https://github.com/RTIInternational/NHLBI-BDC-DMC-HV/tree/main/priority_variables_transform/CARDIA-ingest",

    "Framingham Cohort":
        "https://github.com/RTIInternational/NHLBI-BDC-DMC-HV/tree/main/priority_variables_transform/FHS-ingest",

    ("Cardiovascular Health Study (CHS) Cohort: an NHLBI-funded observational study "
     "of risk factors for cardiovascular disease in adults 65 years or older"):
        "https://github.com/RTIInternational/NHLBI-BDC-DMC-HV/tree/main/priority_variables_transform/CHS-ingest",

    "Hispanic Community Health Study /Study of Latinos (HCHS/SOL)":
        "https://github.com/RTIInternational/NHLBI-BDC-DMC-HV/tree/main/priority_variables_transform/HCHS-ingest",

    "Jackson Heart Study (JHS) Cohort":
        "https://github.com/RTIInternational/NHLBI-BDC-DMC-HV/tree/main/priority_variables_transform/JHS-ingest",

    "Multi-Ethnic Study of Atherosclerosis (MESA) Cohort":
        "https://github.com/RTIInternational/NHLBI-BDC-DMC-HV/tree/main/priority_variables_transform/MESA-ingest",

    "Women's Health Initiative":
        "https://github.com/RTIInternational/NHLBI-BDC-DMC-HV/tree/main/priority_variables_transform/WHI-ingest",

    "Genetic Epidemiology of COPD (COPDGene)":
        "https://github.com/RTIInternational/NHLBI-BDC-DMC-HV/tree/main/priority_variables_transform/COPDGene-ingest"
}

# The local spreadsheet authority
MANIFEST_PATH = "dbgap_variables_priority_cohorts_V2.csv"

# Output directory for results
OUTPUT_DIR = r"c:\temp"

# =============================================================================
# 2. HELPER FUNCTIONS
# =============================================================================

def parse_github_url(url):
    """Convert a GitHub web URL into a GitHub API URL for contents."""
    # Pattern: https://github.com/{owner}/{repo}/tree/{branch}/{path}
    pattern = r"https://github\.com/([^/]+)/([^/]+)/tree/([^/]+)/(.*)"
    match = re.match(pattern, url)
    if not match:
        raise ValueError("Invalid GitHub URL format. Use the /tree/{branch}/{path} format.")

    owner, repo, branch, path = match.groups()
    api_url = f"https://api.github.com/repos/{owner}/{repo}/contents/{path}?ref={branch}"
    return api_url

def clean_accession(val):
    """Standardize PHT/PHV by removing versioning (e.g., pht001234.v1.p1 -> pht001234)."""
    if pd.isna(val):
        return ""
    match = re.search(r"(pht\d+|phv\d+)", str(val).lower())
    return match.group(1) if match else str(val).lower()

# =============================================================================
# 3. MAIN AUDIT LOGIC
# =============================================================================

def run_remote_audit(cohort_name, github_url, manifest_df):
    """Run remote audit to validate GitHub YAMLs against local manifest for a single cohort."""
    print("--- ü©∫ Initializing Remote Mapping Audit ---")
    print(f"üìç Cohort: {cohort_name}\n")

    # Filter for the target study and clean accession columns
    auth_df = manifest_df[manifest_df['Study'].str.contains(cohort_name, na=False, case=False, regex=False)].copy()
    auth_df['pht_clean'] = auth_df['Dataset accession'].apply(clean_accession)
    auth_df['phv_clean'] = auth_df['Variable accession'].apply(clean_accession)

    print(f"‚úÖ Loaded {len(auth_df):,} PHT-PHV mappings from manifest for {cohort_name}.")

    # 2. Fetch YAML list from GitHub
    api_url = parse_github_url(github_url)
    response = requests.get(api_url, timeout=30)
    if response.status_code != 200:
        print(f"‚ùå Failed to fetch GitHub contents: {response.status_code}")
        return

    files = response.json()
    yaml_files = [f for f in files if f['name'].endswith('.yaml')]
    print(f"üì° Found {len(yaml_files)} YAML files on GitHub. Starting Audit...\n")

    mismatches = []
    yaml_errors = []
    structural_issues = []
    file_stats = []

    # 3. Process Remote YAMLs
    for yf in yaml_files:
        print(f"Processing: {yf['name']}...")
        file_violations = 0
        file_phts = set()
        file_structural_issues = 0
        file_phvs_checked = 0

        raw_resp = requests.get(yf['download_url'], timeout=30)
        try:
            config = yaml.safe_load(raw_resp.text)
        except yaml.YAMLError as e:
            error_msg = str(e)
            yaml_errors.append({
                'file': yf['name'],
                'error': error_msg
            })
            print(f"   ‚ö†Ô∏è  [YAML ERROR] Skipping {yf['name']}: {error_msg.split(chr(10))[0]}...")
            # Add to file_stats with ERROR indicator
            file_stats.append({
                'file': yf['name'],
                'phts_used': 'ERROR',
                'phvs_checked': 'ERROR',
                'violations': 'PARSE_ERROR',
                'structural_issues': 'N/A'
            })
            continue

        configs = config if isinstance(config, list) else [config]
        for item in configs:
            if not isinstance(item, dict):
                continue
            derivations = item.get('class_derivations', {})

            for _class_name, details in derivations.items():
                # Ensure details is a dictionary
                if not isinstance(details, dict):
                    issue_msg = f"class_derivations[{_class_name}] is {type(details).__name__}, expected dict"
                    structural_issues.append({
                        'file': yf['name'],
                        'location': f'class_derivations.{_class_name}',
                        'issue': f'Type: {type(details).__name__}',
                        'value_preview': str(details)[:100]
                    })
                    file_structural_issues += 1
                    print(f"   ‚ö†Ô∏è  [STRUCTURE] {issue_msg}")
                    continue

                source_pht = clean_accession(details.get('populated_from'))
                if not source_pht:
                    continue

                file_phts.add(source_pht)
                # Filter manifest for this specific PHT
                authorized_phvs = auth_df[auth_df['pht_clean'] == source_pht]['phv_clean'].tolist()

                slots = details.get('slot_derivations', {})
                if not isinstance(slots, dict):
                    issue_msg = f"slot_derivations is {type(slots).__name__}, expected dict"
                    structural_issues.append({
                        'file': yf['name'],
                        'location': f'class_derivations.{_class_name}.slot_derivations',
                        'issue': f'Type: {type(slots).__name__}',
                        'value_preview': str(slots)[:100]
                    })
                    file_structural_issues += 1
                    print(f"   ‚ö†Ô∏è  [STRUCTURE] {issue_msg}")
                    continue

                for slot_name, slot_details in slots.items():
                    # Ensure slot_details is a dictionary
                    if not isinstance(slot_details, dict):
                        issue_msg = f"slot_derivations[{slot_name}] is {type(slot_details).__name__}, expected dict"
                        structural_issues.append({
                            'file': yf['name'],
                            'location': f'class_derivations.{_class_name}.slot_derivations.{slot_name}',
                            'issue': f'Type: {type(slot_details).__name__}',
                            'value_preview': str(slot_details)[:100]
                        })
                        file_structural_issues += 1
                        print(f"   ‚ö†Ô∏è  [STRUCTURE] {issue_msg}")
                        continue

                    phv_mapped = clean_accession(slot_details.get('populated_from'))

                    if phv_mapped.startswith('phv'):
                        file_phvs_checked += 1
                        # THE TEST: Is this PHV mapped to this PHT in the Master Manifest?
                        if phv_mapped not in authorized_phvs:
                            is_critical = "YES" if slot_name == "associated_participant" else "NO"
                            file_violations += 1

                            mismatches.append({
                                'CRITICAL': is_critical,
                                'Remote_YAML': yf['name'],
                                'PHT': source_pht,
                                'Slot': slot_name,
                                'Invalid_PHV': phv_mapped,
                                'Study_Context': cohort_name
                            })

                            status = "üö® [CRITICAL]" if is_critical == "YES" else "‚ùå [ERROR]"
                            print(f"   {status} {slot_name}: {phv_mapped} is not authorized for {source_pht}")

        # Store statistics for this file
        file_stats.append({
            'file': yf['name'],
            'phts_used': len(file_phts),
            'phvs_checked': file_phvs_checked,
            'violations': file_violations,
            'structural_issues': file_structural_issues
        })

    # 4. Final Reporting
    print("\n" + "="*80)
    print("AUDIT SUMMARY")
    print("="*80)

    # Manifest statistics
    total_phts = auth_df['pht_clean'].nunique()
    total_phvs = auth_df['phv_clean'].nunique()
    print(f"\nüìä Manifest Reference Database ({cohort_name}):")
    print(f"   - Unique PHTs (datasets): {total_phts:,}")
    print(f"   - Unique PHVs (variables): {total_phvs:,}")
    print(f"   - Total PHT-PHV mapping rows: {len(auth_df):,}")

    # Per-file statistics
    if file_stats:
        # Calculate totals, excluding files with errors
        total_phvs_checked = sum(s['phvs_checked'] for s in file_stats if isinstance(s['phvs_checked'], int))
        files_with_violations = len([s for s in file_stats if isinstance(s['violations'], int) and s['violations'] > 0])
        files_with_errors = len([s for s in file_stats if s['violations'] == 'PARSE_ERROR'])
        total_structural_issues = sum(
            s['structural_issues'] for s in file_stats
            if isinstance(s['structural_issues'], int)
        )

        print("\nüìÇ YAML File Processing Summary:")
        print(f"   - Files processed: {len(file_stats)}")
        print(f"   - Files with parse errors: {files_with_errors}")
        print(f"   - Total PHVs checked across all files: {total_phvs_checked:,}")
        print(f"   - Files with violations: {files_with_violations}")
        print(f"   - Total structural issues found: {total_structural_issues}")

        print("\nüìã Per-File Breakdown:")
        print(f"   {'File':<35} {'PHTs':<6} {'PHVs':<8} {'Violations':<12} {'Struct Issues':<14}")
        print(f"   {'-'*35} {'-'*6} {'-'*8} {'-'*12} {'-'*14}")
        for stat in file_stats:
            if stat['violations'] == 'PARSE_ERROR':
                status = "‚ö†Ô∏è "
                phts_display = "N/A"
                phvs_display = "N/A"
                viol_display = "PARSE_ERR"
                struct_display = "N/A"
            else:
                status = "‚ùå" if stat['violations'] > 0 else "‚úÖ"
                phts_display = str(stat['phts_used'])
                phvs_display = str(stat['phvs_checked'])
                viol_display = str(stat['violations'])
                struct_display = str(stat['structural_issues'])

            print(
                f"   {status} {stat['file']:<33} {phts_display:<6} "
                f"{phvs_display:<8} {viol_display:<12} {struct_display:<14}"
            )

    if yaml_errors:
        print(f"\n‚ö†Ô∏è  {len(yaml_errors)} YAML file(s) had parsing errors and were skipped:")
        for err in yaml_errors:
            print(f"   - {err['file']}")
            # Extract just the first line of error for summary
            error_line = err['error'].split('\n')[0] if '\n' in err['error'] else err['error']
            print(f"     Reason: {error_line}")

    if structural_issues:
        print(f"\n‚ö†Ô∏è  {len(structural_issues)} structural issue(s) found in YAML files:")
        # Group by file for better readability
        files_with_issues = {}
        for issue in structural_issues:
            file_name = issue['file']
            if file_name not in files_with_issues:
                files_with_issues[file_name] = []
            files_with_issues[file_name].append(issue)

        for file_name, issues in files_with_issues.items():
            print(f"   üìÑ {file_name} ({len(issues)} issue(s)):")
            for issue in issues[:5]:  # Show first 5 issues per file
                print(f"      ‚Ä¢ Location: {issue['location']}")
                print(f"        {issue['issue']}")
                if len(issue['value_preview']) < 100:
                    print(f"        Value: {issue['value_preview']}")
                else:
                    print(f"        Value: {issue['value_preview']}...")
            if len(issues) > 5:
                print(f"      ... and {len(issues) - 5} more issue(s)")

    if mismatches:
        # Create output filename from cohort name
        cohort_short = cohort_name.split()[0].replace('(', '').replace(')', '')
        output_file = os.path.join(OUTPUT_DIR, f"audit_results_{cohort_short}.csv")

        df_out = pd.DataFrame(mismatches).sort_values(by='CRITICAL', ascending=False)
        df_out.to_csv(output_file, index=False)
        critical_count = len([m for m in mismatches if m['CRITICAL'] == 'YES'])

        print(f"\n‚ùå {len(mismatches)} mapping violation(s) found:")
        print(f"   - {critical_count} CRITICAL violations (associated_participant field)")
        print(f"   - {len(mismatches) - critical_count} NON-CRITICAL violations (other fields)")

        print("\nüîç Detailed Findings:")
        for i, m in enumerate(mismatches, 1):
            status = "üö® CRITICAL" if m['CRITICAL'] == 'YES' else "‚ùå ERROR"
            print(f"   {i}. [{status}] {m['Remote_YAML']}")
            print(f"      PHT: {m['PHT']} | Slot: {m['Slot']} | Invalid PHV: {m['Invalid_PHV']}")

        print(f"\nüìÑ Full report saved to: {output_file}")
    else:
        print("\n‚úÖ SUCCESS: All remote mappings are authorized by the Master Manifest.")


def main():
    """Run remote audit for all configured cohorts."""
    # Ensure proper encoding for console output
    import sys
    if sys.stdout.encoding != 'utf-8':
        sys.stdout.reconfigure(encoding='utf-8')

    print("="*80)
    print("BDC REMOTE LOGIC AUDITOR - MULTI-COHORT RUN")
    print("="*80)
    print(f"\nüîç Processing {len(COHORT_CONFIGS)} cohorts...\n")

    # Create output directory if it doesn't exist
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # Load the manifest once
    if not os.path.exists(MANIFEST_PATH):
        print(f"‚ùå CRITICAL: Manifest file {MANIFEST_PATH} not found.")
        return

    manifest_df = pd.read_csv(MANIFEST_PATH)

    # Process each cohort
    for idx, (cohort_name, github_url) in enumerate(COHORT_CONFIGS.items(), 1):
        print("\n" + "="*80)
        print(f"COHORT {idx}/{len(COHORT_CONFIGS)}")
        print("="*80)

        try:
            run_remote_audit(cohort_name, github_url, manifest_df)
        except Exception as e:
            print(f"\n‚ùå ERROR processing {cohort_name}: {str(e)}")
            print("Continuing to next cohort...\n")

        # Add spacing between cohorts
        print("\n")

    print("="*80)
    print("‚úÖ MULTI-COHORT AUDIT COMPLETE")
    print("="*80)
    print(f"\nüìÅ Results saved in: {OUTPUT_DIR}/")
    print(f"   {len(COHORT_CONFIGS)} cohort(s) processed\n")


if __name__ == "__main__":
    main()
