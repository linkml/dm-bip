{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6739dc-7468-44b2-b00c-3ca089958005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import subprocess\n",
    "from typing import Optional\n",
    "import yaml\n",
    "\n",
    "from linkml.validator.loaders import TsvLoader\n",
    "from linkml.utils.schema_builder import SchemaBuilder\n",
    "\n",
    "from linkml_runtime.linkml_model import SlotDefinition\n",
    "from linkml_runtime import SchemaView\n",
    "\n",
    "from linkml_map.session import Session\n",
    "from linkml_map.transformer.object_transformer import ObjectTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e2e25a-ed25-4c47-8af4-e13f55365537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix malformed yaml\n",
    "def quote_expr_values(yaml_text):\n",
    "    def replacer(match):\n",
    "        indent = match.group(1)\n",
    "        value = match.group(2).strip()\n",
    "        \n",
    "        if value.startswith('\"') or value.startswith(\"'\"):\n",
    "            if \"#\" in value and (value.endswith('\"') or value.endswith(\"'\")):\n",
    "                quote_char = value[0]\n",
    "                strip_comment = value[1:-1].split('#')[0].strip()\n",
    "                return f'{indent}expr: {quote_char}{strip_comment}{quote_char}'\n",
    "            return match.group(0)\n",
    "        \n",
    "        value = value.split('#')[0].strip()\n",
    "        if re.match(r'^[\\w{}\\s\\*\\+\\-/().]+$', value):\n",
    "            return f'{indent}expr: \"{value}\"'\n",
    "        return match.group(0)\n",
    "\n",
    "    pattern = re.compile(r'^(\\s*)expr:\\s+(.*)', re.MULTILINE)\n",
    "    return pattern.sub(replacer, yaml_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b3a53f-db72-4818-8377-50863b79ec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_quantity_subslots(slot_derivs, doc_index, parent_slot_name, populated_from, known_subslots):\n",
    "    quantity_subslots = {}\n",
    "\n",
    "    # 1. Pull nested subslots under e.g. range_low: { value_decimal: ... }\n",
    "    nested = slot_derivs.pop(parent_slot_name, {}) if isinstance(slot_derivs.get(parent_slot_name), dict) else {}\n",
    "\n",
    "    # 2. Scan for both nested and top-level flat entries\n",
    "    for subkey in known_subslots:\n",
    "        # Support flat key: e.g., value_quantity.unit\n",
    "        flat_key = f\"{parent_slot_name}.{subkey}\"\n",
    "\n",
    "        entry = (\n",
    "            nested.pop(subkey, None)\n",
    "            or slot_derivs.pop(flat_key, None)\n",
    "            or slot_derivs.pop(subkey, None)  # e.g., value_decimal defined at top-level\n",
    "        )\n",
    "\n",
    "        if entry:\n",
    "            if isinstance(entry, dict):\n",
    "                pf = entry.get(\"populated_from\")\n",
    "                expr = entry.get(\"expr\")\n",
    "\n",
    "                if pf and isinstance(pf, dict) and \"expr\" in pf:\n",
    "                    quantity_subslots[subkey] = {\"expr\": pf[\"expr\"]}\n",
    "                elif expr:\n",
    "                    quantity_subslots[subkey] = {\"expr\": expr}\n",
    "                elif pf is None:\n",
    "                    raise ValueError(f\"[Doc {doc_index}] `{subkey}` in `{parent_slot_name}` has empty `populated_from:` and no `expr:`\")\n",
    "                elif isinstance(pf, str):\n",
    "                    quantity_subslots[subkey] = {\"populated_from\": pf}\n",
    "                else:\n",
    "                    raise ValueError(f\"[Doc {doc_index}] Malformed `{subkey}` in `{parent_slot_name}`: {entry}\")\n",
    "            else:\n",
    "                raise ValueError(f\"[Doc {doc_index}] Unexpected format for `{subkey}` in `{parent_slot_name}`: {entry}\")\n",
    "\n",
    "    if quantity_subslots:\n",
    "        return {\n",
    "            \"object_derivations\": [{\n",
    "                \"class_derivations\": {\n",
    "                    \"Quantity\": {\n",
    "                        \"populated_from\": populated_from,\n",
    "                        \"slot_derivations\": quantity_subslots\n",
    "                    }\n",
    "                }\n",
    "            }]\n",
    "        }\n",
    "\n",
    "    return None\n",
    "\n",
    "def refactor_value_quantity(documents):\n",
    "    updated_docs = []\n",
    "\n",
    "    quantity_subslots = [\"value_decimal\", \"value_concept\", \"value_integer\", \"unit\"]\n",
    "\n",
    "    for doc_index, doc in enumerate(documents):\n",
    "        cd = doc.get(\"class_derivations\", {})\n",
    "        for cls_name, cls_info in cd.items():\n",
    "            slot_derivs = cls_info.get(\"slot_derivations\", {})\n",
    "            populated_from = cls_info.get(\"populated_from\")\n",
    "\n",
    "            # Apply to each target \"container\" slot\n",
    "            for target_slot in [\"value_quantity\", \"range_low\", \"range_high\"]:\n",
    "                result = extract_quantity_subslots(\n",
    "                    slot_derivs,\n",
    "                    doc_index,\n",
    "                    target_slot,\n",
    "                    populated_from,\n",
    "                    quantity_subslots\n",
    "                )\n",
    "                if result:\n",
    "                    slot_derivs[target_slot] = result\n",
    "\n",
    "        updated_docs.append(doc)\n",
    "\n",
    "    return updated_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cf4540-06ce-498f-a45b-3eb7e3e4ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_populated_from_with_pht(documents, phv_to_pht):\n",
    "    def find_first_phv_in_slot(slot_derivations):\n",
    "        for slot_value in slot_derivations.values():\n",
    "            if isinstance(slot_value, dict):\n",
    "                pf = slot_value.get(\"populated_from\")\n",
    "                expr = slot_value.get(\"expr\")\n",
    "\n",
    "                if isinstance(pf, str) and pf.startswith(\"phv\"):\n",
    "                    return pf\n",
    "                if isinstance(expr, str):\n",
    "                    match = re.search(r\"(phv\\d{8})\", expr)\n",
    "                    if match:\n",
    "                        return match.group(1)\n",
    "        return None\n",
    "\n",
    "    def update_class_derivations(cls_derivations, doc_index, context=\"root\", parent_pht=None):\n",
    "        for cls_name, cls_info in cls_derivations.items():\n",
    "            slot_derivs = cls_info.get(\"slot_derivations\", {})\n",
    "            pf = cls_info.get(\"populated_from\")\n",
    "\n",
    "            if pf == \"FHS\":\n",
    "                phv = find_first_phv_in_slot(slot_derivs)\n",
    "                if phv and phv in phv_to_pht:\n",
    "                    new_pf = phv_to_pht[phv]\n",
    "                    cls_info[\"populated_from\"] = new_pf\n",
    "                    parent_pht = new_pf  # propagate to children\n",
    "                    # print(f\"✅ Updated {context}.{cls_name} populated_from: {phv} -> {new_pf}\")\n",
    "                elif parent_pht:\n",
    "                    cls_info[\"populated_from\"] = parent_pht\n",
    "                else:\n",
    "                    print(f\"⚠️ Warning: No matching phv for {context}.{cls_name} in doc {doc_index}\")\n",
    "\n",
    "            # Recurse into nested object_derivations\n",
    "            for slot_name, slot_value in slot_derivs.items():\n",
    "                if isinstance(slot_value, dict) and \"object_derivations\" in slot_value:\n",
    "                    for obj in slot_value[\"object_derivations\"]:\n",
    "                        inner_cls_derivs = obj.get(\"class_derivations\")\n",
    "                        if inner_cls_derivs:\n",
    "                            update_class_derivations(inner_cls_derivs, doc_index, context=f\"{context}.{cls_name}.{slot_name}\", parent_pht=parent_pht)\n",
    "\n",
    "    for doc_index, doc in enumerate(documents):\n",
    "        top_cd = doc.get(\"class_derivations\", {})\n",
    "        update_class_derivations(top_cd, doc_index)\n",
    "\n",
    "    return documents\n",
    "\n",
    "def load_phv_to_pht_map(file_path):\n",
    "    with open(file_path) as f:\n",
    "        return dict(line.strip().split(\": \") for line in f if line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0426938-49b9-401f-98cb-660f4c2a4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_misindented_value_mappings(yaml_text):\n",
    "    lines = yaml_text.splitlines()\n",
    "    fixed = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        fixed.append(line)\n",
    "        if re.match(r'^\\s+populated_from:\\s+\\S+', line):\n",
    "            pf_indent = len(line) - len(line.lstrip())\n",
    "            # Peek ahead to see if value_mappings is wrongly indented\n",
    "            if i + 1 < len(lines) and lines[i + 1].lstrip().startswith(\"value_mappings:\"):\n",
    "                vm_line = lines[i + 1]\n",
    "                vm_indent = len(vm_line) - len(vm_line.lstrip())\n",
    "                if vm_indent > pf_indent:\n",
    "                    # Dedent value_mappings\n",
    "                    fixed.append(\" \" * pf_indent + vm_line.lstrip())\n",
    "                    i += 1\n",
    "                    # Dedent any following lines more indented than vm_indent\n",
    "                    while i + 1 < len(lines):\n",
    "                        peek = lines[i + 1]\n",
    "                        peek_indent = len(peek) - len(peek.lstrip())\n",
    "                        if peek_indent > vm_indent:\n",
    "                            i += 1\n",
    "                            fixed.append(\" \" * (pf_indent + 2) + peek.lstrip())\n",
    "                        else:\n",
    "                            break\n",
    "        i += 1\n",
    "    return \"\\n\".join(fixed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0340c69-6b02-4052-88ef-01a137787b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_str_fields_expr(parsed_docs):\n",
    "    for doc in parsed_docs:\n",
    "        for cls in doc.get(\"class_derivations\", {}).values():\n",
    "            slot_derivs = cls.get(\"slot_derivations\", {})\n",
    "            for slot_name, slot_value in list(slot_derivs.items()):\n",
    "                if isinstance(slot_value, str):\n",
    "                    slot_derivs[slot_name] = {\"expr\": f\"'{slot_value}'\"}\n",
    "    return parsed_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f980ce7-554e-4459-88b9-cec08500ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quote_expr_strings(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        new_obj = {}\n",
    "        for k, v in obj.items():\n",
    "            if k == \"expr\" and isinstance(v, str):\n",
    "                # Only add quotes if not already quoted\n",
    "                if not (v.startswith(\"'\") and v.endswith(\"'\")):\n",
    "                    v = f\"'{v}'\"\n",
    "            new_obj[k] = quote_expr_strings(v)\n",
    "        return new_obj\n",
    "    elif isinstance(obj, list):\n",
    "        return [quote_expr_strings(i) for i in obj]\n",
    "    else:\n",
    "        return obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb6bbd4-7734-43ee-8504-8711116f9fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPR_PATTERN = re.compile(r'\\b(case)\\b|[()+*/<>]|(?<!\\w)-(?=\\w)')\n",
    "def is_const_expr(expr: str) -> bool:\n",
    "    expr = expr.strip().strip(\"'\\\"\")\n",
    "    if not expr:\n",
    "        return False\n",
    "    # If the expression contains any expression-like elements, it's not constant\n",
    "    if EXPR_PATTERN.search(expr):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def const_expr_to_value_in_slot(slot_deriv: dict) -> None:\n",
    "    if not isinstance(slot_deriv, dict):\n",
    "        return\n",
    "    expr = slot_deriv.get(\"expr\")\n",
    "    if isinstance(expr, str) and is_const_expr(expr):\n",
    "        slot_deriv[\"value\"] = expr.strip(\"'\\\"\")\n",
    "        slot_deriv.pop(\"expr\", None)\n",
    "        slot_deriv.setdefault(\"range\", \"string\")\n",
    "\n",
    "def const_expr_to_value_in_class(class_deriv: dict) -> None:\n",
    "    slot_derivs = class_deriv.get(\"slot_derivations\", {})\n",
    "    for slot_deriv in slot_derivs.values():\n",
    "        const_expr_to_value_in_slot(slot_deriv)\n",
    "\n",
    "        # Recurse into object_derivations\n",
    "        if isinstance(slot_deriv, dict):\n",
    "            for obj in slot_deriv.get(\"object_derivations\", []):\n",
    "                for obj in slot_deriv.get(\"object_derivations\", []):\n",
    "                    if isinstance(obj, dict) and \"slot_derivations\" in obj:\n",
    "                        const_expr_to_value_in_class(obj)\n",
    "\n",
    "\n",
    "def const_expr_to_value(parsed_docs: list[dict]) -> list[dict]:\n",
    "    for doc in parsed_docs:\n",
    "        for class_deriv in doc.get(\"class_derivations\", {}).values():\n",
    "            const_expr_to_value_in_class(class_deriv)\n",
    "    return parsed_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c9241f-2ccc-41a9-b96f-30b50d526b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_inline_comments(parsed_docs: list[dict]) -> list[dict]:\n",
    "    def extract_comment_from_value(val: str) -> tuple[str, Optional[str]]:\n",
    "        if \"#\" in val:\n",
    "            main, comment = val.split(\"#\", 1)\n",
    "            return main.strip(), comment.strip()\n",
    "        return val, None\n",
    "\n",
    "    def fix_slot(slot: dict):\n",
    "        if not isinstance(slot, dict):\n",
    "            return\n",
    "        for field in (\"value\", \"expr\"):\n",
    "            val = slot.get(field)\n",
    "            if isinstance(val, str) and \"#\" in val:\n",
    "                clean_val, comment = extract_comment_from_value(val)\n",
    "                slot[field] = clean_val\n",
    "                if comment:\n",
    "                    slot.setdefault(\"comments\", []).append(comment)\n",
    "\n",
    "    def recurse_class(class_deriv: dict):\n",
    "        for slot_deriv in class_deriv.get(\"slot_derivations\", {}).values():\n",
    "            fix_slot(slot_deriv)\n",
    "            for obj in slot_deriv.get(\"object_derivations\", []):\n",
    "                if isinstance(obj, dict):\n",
    "                    recurse_class(obj)\n",
    "\n",
    "    for doc in parsed_docs:\n",
    "        for class_deriv in doc.get(\"class_derivations\", {}).values():\n",
    "            recurse_class(class_deriv)\n",
    "\n",
    "    return parsed_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ef28a-ed34-4c5e-acf3-59a9ad410732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_nested_expr_under_populated_from(yaml_text: str) -> str:\n",
    "    lines = yaml_text.splitlines()\n",
    "    out_lines = []\n",
    "    i = 0\n",
    "\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "\n",
    "        if line.lstrip().startswith(\"populated_from:\"):\n",
    "            indent = len(line) - len(line.lstrip())\n",
    "            next_line = lines[i + 1] if i + 1 < len(lines) else \"\"\n",
    "\n",
    "            if next_line.lstrip().startswith(\"expr:\"):\n",
    "                # Rewrite: replace populated_from + expr with dedented expr\n",
    "                out_lines.append(\" \" * indent + next_line.lstrip())\n",
    "                i += 2\n",
    "\n",
    "                # Append any deeper-indented lines\n",
    "                while i < len(lines):\n",
    "                    peek = lines[i]\n",
    "                    if len(peek) - len(peek.lstrip()) > indent:\n",
    "                        out_lines.append(\" \" * (indent + 2) + peek.lstrip())\n",
    "                        i += 1\n",
    "                    else:\n",
    "                        break\n",
    "                continue\n",
    "\n",
    "        out_lines.append(line)\n",
    "        i += 1\n",
    "\n",
    "    return \"\\n\".join(out_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332b6852-66d5-42ee-8d01-1e089b2382d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_braces_in_exprs(yaml_text: str) -> str:\n",
    "    lines = yaml_text.splitlines()\n",
    "    new_lines = []\n",
    "    in_expr_block = False\n",
    "\n",
    "    for line in lines:\n",
    "        stripped = line.lstrip()\n",
    "        if stripped.startswith(\"expr:\"):\n",
    "            # Replace braces on the line\n",
    "            line = re.sub(r\"\\{([^}]+)\\}\", r\"\\1\", line)\n",
    "            in_expr_block = True\n",
    "        elif in_expr_block:\n",
    "            indent = len(line) - len(stripped)\n",
    "            if indent > 0:\n",
    "                # Still part of the expression block\n",
    "                line = re.sub(r\"\\{([^}]+)\\}\", r\"\\1\", line)\n",
    "            else:\n",
    "                in_expr_block = False\n",
    "        new_lines.append(line)\n",
    "\n",
    "    return \"\\n\".join(new_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85ce69b-8bac-4b3b-b0e3-ca876e8c424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quote_unquoted_exprs(yaml_text: str) -> str:\n",
    "    lines = yaml_text.splitlines()\n",
    "    out_lines = []\n",
    "    i = 0\n",
    "\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        stripped = line.lstrip()\n",
    "        indent = len(line) - len(stripped)\n",
    "\n",
    "        if stripped.startswith(\"expr:\"):\n",
    "            expr_val = stripped[len(\"expr:\"):].lstrip()\n",
    "\n",
    "            # Skip already quoted expressions\n",
    "            if expr_val.startswith((\"'\", '\"')):\n",
    "                out_lines.append(line)\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            # Start quoting\n",
    "            quoted_line = \" \" * indent + \"expr: \\\"\"\n",
    "            remainder = expr_val\n",
    "            i += 1\n",
    "\n",
    "            # Collect multiline expr block (indented more than current line)\n",
    "            while i < len(lines):\n",
    "                next_line = lines[i]\n",
    "                next_indent = len(next_line) - len(next_line.lstrip())\n",
    "                if next_indent > indent:\n",
    "                    remainder += \"\\\\n\" + next_line.strip()\n",
    "                    i += 1\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            # ✅ FIX: Ensure phv000#### references are wrapped in braces\n",
    "            remainder = re.sub(r'\\b(phv\\d{8})\\b', r'{\\1}', remainder)\n",
    "\n",
    "            # ✅ Quote and escape\n",
    "            quoted_line += remainder.replace('\"', '\\\\\"') + \"\\\"\"\n",
    "            out_lines.append(quoted_line)\n",
    "        else:\n",
    "            out_lines.append(line)\n",
    "            i += 1\n",
    "\n",
    "    return \"\\n\".join(out_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1995fd78-b9a7-4760-ab4a-fe08e3499b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_dir = Path(\"/sbgenomics/workspace/NHLBI-BDC-DMC-HV/priority_variables_transform/FHS\")\n",
    "data_dir = \"/sbgenomics/workspace/output/FHS_v31_c1\"\n",
    "output_dir = Path(\"/sbgenomics/workspace/NHLBI-BDC-DMC-HV/priority_variables_transform/FHS-ingest\")\n",
    "\n",
    "# Not complete: bld_pressure\n",
    "# unreasolvable issues: ven_thromb, valv_hrtdis, whtbld_ct\n",
    "# SKIP_BASES = {\"afib\", # \"fast_gluc_bld\", \"bld_pressure\",\n",
    "#               # \"glucose_bld\", \"hdl\", \"ldl\", \"hip_circ\",\n",
    "#               # \"alt_sgpt\", \"bdy_hgt\", \"bdy_wgt\",  \"cig_smok\", \"creat_bld\", \"edu_lvl\",\n",
    "#               # \"fam_income\", \"hist_cor_angio\", \"hist_cor_bypg\", \"hist_my_inf\", \"hrtrt\", \"hypertension\", \"nt_bnp\", \"stroke\",\n",
    "#               # \"tak_betablk\", \"tak_calchanblk\", \"tak_diuret\", \"tot_chol_bld\", \"triglyc_bld\", \"troponin\", \"waist_circ\",\n",
    "#              }\n",
    "SKIP_BASES = {\"bld_pressure\"}\n",
    "RUN_BASES = {\"demography\"}\n",
    "\n",
    "for yaml_file in spec_dir.glob(\"*.yaml\"):\n",
    "    base = yaml_file.stem  # Strip .yaml\n",
    "    output_file = f\"{output_dir}/{base}.yaml\"\n",
    "\n",
    "    # if base in SKIP_BASES:\n",
    "    #     # print(f\"⏭️ Skipping {base}\")\n",
    "    #     continue\n",
    "\n",
    "    if base not in RUN_BASES:\n",
    "    # print(f\"⏭️ Skipping {base}\")\n",
    "        continue\n",
    "\n",
    "    # if Path(output_file).exists():\n",
    "    #     print(f\"⏭️ Output exists, skipping {base}\")\n",
    "    #     continue\n",
    "    \n",
    "    print(base)\n",
    "\n",
    "    ### Load and fix issues then process YAML\n",
    "    raw = \"\\n\".join(line.rstrip() for line in yaml_file.read_text().splitlines())\n",
    "    # Fix trailing spaces\n",
    "    pre_yaml = \"\\n\".join(line.rstrip() for line in raw.splitlines())\n",
    "\n",
    "    # Fix when there is not a space after a colon\n",
    "    pre_yaml = re.sub(r'^(\\s*[^#:\\n]+?):(?=\\S)', r'\\1: ', pre_yaml, flags=re.MULTILINE)\n",
    "    # quoted_fixed = quote_expr_values(colon_fixed)\n",
    "\n",
    "    # Fix improper indenting on value_mappings\n",
    "    pre_yaml = fix_misindented_value_mappings(pre_yaml)\n",
    "\n",
    "    # Fix improper nesting of expr under populated_from\n",
    "    pre_yaml = fix_nested_expr_under_populated_from(pre_yaml)\n",
    "\n",
    "    # Add quoting around expressions, including multiline\n",
    "    pre_yaml = quote_unquoted_exprs(pre_yaml)\n",
    "\n",
    "    # # Fix improper nesting of expr under populated_from\n",
    "    # pre_yaml = strip_braces_in_exprs(pre_yaml)\n",
    "    \n",
    "    # Fix UNKNOWN participant in certain files.\n",
    "    pre_yaml = re.sub(\n",
    "        r'(associated_participant:\\n\\s+)(expr:\\s+\\'\\'?UNKNOWN\\'\\'?)',\n",
    "        r'\\1populated_from: phv00277066',\n",
    "        pre_yaml\n",
    "    )\n",
    "\n",
    "    # Split blocks class derivations into proper YAML blocks\n",
    "    pre_yaml = re.split(r'(?<=\\n)(?=^\\s*class_derivations:\\s*)', pre_yaml, flags=re.MULTILINE)\n",
    "\n",
    "    # Parse the yaml\n",
    "    parsed_yaml = [yaml.safe_load(doc) for doc in pre_yaml]\n",
    "\n",
    "    # convert const expressions to value entity\n",
    "    parsed_yaml = const_expr_to_value(parsed_yaml)\n",
    "\n",
    "    # turn quantity \n",
    "    parsed_yaml = refactor_value_quantity(parsed_yaml)\n",
    "\n",
    "    # Run the shell command to regenerate phv dict\n",
    "    result = subprocess.run(\n",
    "        f\"\"\"for phv in $(grep -ho 'phv[0-9]\\\\{{8\\\\}}' {spec_dir}/{base}.yaml | sort -u); do \\\n",
    "        grep -l \"$phv\" {data_dir}/*.tsv | \\\n",
    "        sed -E \"s|.*/(pht[0-9]{{6,}}).tsv|$phv: \\\\1|\"; done\"\"\",\n",
    "        shell=True, check=True, capture_output=True, text=True,\n",
    "    )\n",
    "    phv_to_pht = dict(line.split(\": \") for line in result.stdout.strip().splitlines())\n",
    "\n",
    "    parsed_yaml = update_populated_from_with_pht(parsed_yaml, phv_to_pht)\n",
    "\n",
    "    parsed_yaml = extract_inline_comments(parsed_yaml)\n",
    "\n",
    "    # Quote Expr strings\n",
    "    # parsed_yaml = quote_expr_strings(parsed_yaml)\n",
    "\n",
    "    # Dump to YAML\n",
    "    with open(output_file, \"w\") as f:\n",
    "        yaml.dump(parsed_yaml, f, sort_keys=False, allow_unicode=True)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3fc909-c089-4bf3-aa9c-6de95b499b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pre_yaml[1])\n",
    "# print(yaml.dump(pht_replace_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5e21c5-c447-46e9-9095-c5ba9cdd5b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the shell command to regenerate phv_to_pht.txt\n",
    "base = \"bdy_wgt\"\n",
    "subprocess.run(\n",
    "    f\"\"\"for phv in $(grep -ho 'phv[0-9]\\\\{{8\\\\}}' {spec_dir}/{base}.yaml | sort -u); do \\\n",
    "    grep -l \"$phv\" {data_dir}/*.tsv | \\\n",
    "    sed -E \"s|.*/(pht[0-9]{{6,}}).tsv|$phv: \\\\1|\"; done > phv_to_pht.txt\"\"\",\n",
    "    shell=True, check=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375c25d4-2729-4fba-a018-d933f47cbd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set base name\n",
    "spec_dir = \"NHLBI-BDC-DMC-HV/priority_variables_transform/FHS\"\n",
    "base = \"afib\"\n",
    "data_dir = \"output/FHS_v31_c1\"\n",
    "\n",
    "# Run the shell command to regenerate phv_to_pht.txt\n",
    "subprocess.run(\n",
    "    f\"\"\"for phv in $(grep -ho 'phv[0-9]\\\\{{8\\\\}}' {spec_dir}/{base}.yaml | sort -u); do \\\n",
    "    grep -l \"$phv\" {data_dir}/*.tsv | \\\n",
    "    sed -E \"s|.*/(pht[0-9]{{6,}}).tsv|$phv: \\\\1|\"; done > phv_to_pht.txt\"\"\",\n",
    "    shell=True, check=True,\n",
    ")\n",
    "\n",
    "# Load and process the YAML\n",
    "raw = Path(f\"NHLBI-BDC-DMC-HV/priority_variables_transform/FHS/{base}.yaml\").read_text()\n",
    "quoted_fixed = quote_expr_values(raw)\n",
    "split_blocks = re.split(r'(?<=\\n)(?=^\\s*class_derivations:\\s*)', quoted_fixed, flags=re.MULTILINE)\n",
    "parsed_docs = [yaml.safe_load(doc) for doc in split_blocks]\n",
    "\n",
    "refactored_docs = refactor_value_quantity(parsed_docs)\n",
    "\n",
    "phv_to_pht = load_phv_to_pht_map(\"NHLBI-BDC-DMC-HV/priority_variables_transform/FHS/phv_to_pht.txt\")\n",
    "\n",
    "pht_replace_docs = update_populated_from_with_pht(refactored_docs, phv_to_pht)\n",
    "\n",
    "# Dump to YAML\n",
    "with open(f\"NHLBI-BDC-DMC-HV/priority_variables_transform/FHS-ingest/{base}.yaml\", \"w\") as f:\n",
    "    yaml.dump(pht_replace_docs, f, sort_keys=False, allow_unicode=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f59373-e14f-48ab-9472-5e560e202d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Person - top level class\n",
    "person_yaml = yaml.safe_load(\"\"\"\n",
    "class_derivations:\n",
    "  Person:\n",
    "    populated_from: pht000009\n",
    "    slot_derivations:\n",
    "      species:\n",
    "        expr: \"'Homo Sapiens'\"\n",
    "      identity:\n",
    "        populated_from: dbGaP_Subject_ID\n",
    "\"\"\")\n",
    "\n",
    "# # Dump to YAML\n",
    "# with open(var_dir + \"person\" + \".yaml\", \"w\") as f:\n",
    "#     yaml.dump(person_yaml, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6956b1d2-bcc6-47f8-8b35-763c7074f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sv = SchemaView(\"/sbgenomics/workspace/output/Schema_FHS_v31_c1/schema-automator-data/Schema_FHS_v31_c1.yaml\")\n",
    "source_schema = source_sv.schema\n",
    "\n",
    "target_sv = SchemaView(\"/sbgenomics/workspace/NHLBI-BDC-DMC-HM/src/bdchm/schema/bdchm.yaml\")\n",
    "target_schema = target_sv.schema\n",
    "\n",
    "var_dir = \"/sbgenomics/workspace/NHLBI-BDC-DMC-HV/priority_variables_transform/FHS-ingest/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876642b2-8b28-4e39-8b12-4ca7822cc0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_spec = person_yaml\n",
    "\n",
    "data_loader = TsvLoader(\"/sbgenomics/workspace/output/FHS_v31_c1/pht000009.tsv\")\n",
    "data_rows = data_loader.iter_instances()\n",
    "\n",
    "first_row = next(data_rows)\n",
    "cur_row = first_row\n",
    "\n",
    "# Create ObjectTransformer and apply transformation\n",
    "transformer = ObjectTransformer(unrestricted_eval=True)\n",
    "transformer.source_schemaview = SchemaView(source_schema)\n",
    "transformer.target_schemaview = SchemaView(target_schema)\n",
    "transformer.create_transformer_specification(transform_spec)\n",
    "\n",
    "result = transformer.map_object(cur_row, source_type=\"pht000009\")\n",
    "\n",
    "print(result)\n",
    "print(\"Transformation Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce73026a-6662-4abe-bfbc-5c737024a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participant - top level class for study data\n",
    "participant_yaml = yaml.safe_load(\"\"\"\n",
    "class_derivations:\n",
    "  Participant:\n",
    "    populated_from: pht000395\n",
    "    slot_derivations:\n",
    "      # associated_participant: \n",
    "      #   populated_from: phv00007675\n",
    "      identity:\n",
    "        populated_from: dbGaP_Subject_ID\n",
    "      member_of_research_study:\n",
    "        expr: \"'FHS'\"\n",
    "\"\"\")\n",
    "\n",
    "# # Dump to YAML\n",
    "# with open(var_dir + \"participant\" + \".yaml\", \"w\") as f:\n",
    "#     yaml.dump(participant_yaml, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c43d7ea-4564-48c3-a2a6-3c837e0b14dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MeasurementObservation class derivations\n",
    "bdy_hgt = refactored_docs\n",
    "# bdy_hgt = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"bdy_hgt\" + \".yaml\")))\n",
    "# bdy_wgt = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"bdy_wgt\" + \".yaml\")))\n",
    "# bmi = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"bmi\" + \".yaml\")))\n",
    "# bp_diastolic = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"bp_diastolic\" + \".yaml\")))\n",
    "# bp_systolic = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"bp_systolic\" + \".yaml\")))\n",
    "# fev1 = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"fev1\" + \".yaml\")))\n",
    "# fev1_fvc = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"fev1_fvc\" + \".yaml\")))\n",
    "# fvc = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"fvc\" + \".yaml\")))\n",
    "# hrt_rt = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"hrt_rt\" + \".yaml\")))\n",
    "# spo2 = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"spo2\" + \".yaml\")))\n",
    "\n",
    "# Get the demography slot on Participants class\n",
    "participant_cls = participant_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Participant\", {})\n",
    "participant_exposures_slot = participant_cls.setdefault(\"slot_derivations\", {}).setdefault(\"exposures\", {})\n",
    "\n",
    "# Add the Demography object_derivation to the demography slot\n",
    "participant_exposures_slot.setdefault(\"object_derivations\", bdy_hgt)\n",
    "# participant_exposures_slot.setdefault(\"object_derivations\", [\n",
    "#     bdy_hgt,\n",
    "#     tak_betablk,\n",
    "#     tak_adrenergics,\n",
    "#     tak_cort_steroid_resp,\n",
    "#     tak_cort_steroid_oral,\n",
    "#     tak_anabolic_steroid,\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d38cb8-ced7-46d3-8685-84d100e98a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_spec = participant_yaml\n",
    "\n",
    "input_data = cur_row\n",
    "\n",
    "# Create ObjectTransformer and apply transformation\n",
    "transformer = ObjectTransformer(unrestricted_eval=True)\n",
    "transformer.source_schemaview = SchemaView(source_schema)\n",
    "transformer.target_schemaview = SchemaView(target_schema)\n",
    "transformer.create_transformer_specification(transform_spec)\n",
    "\n",
    "result = transformer.map_object(input_data, source_type=\"pht000009\")\n",
    "\n",
    "print(result)\n",
    "print(\"Transformation Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd2ea45-fd3a-41cf-b3c7-b35599939f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with one simple condition\n",
    "angina = yaml.safe_load(open(str(var_dir + \"angina\" + \".yaml\")))\n",
    "# print(yaml.dump(angina))\n",
    "\n",
    "# Get the conditions slot on Participants class\n",
    "participant_cls = participant_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Participant\", {})\n",
    "participant_exposures_slot = participant_cls.setdefault(\"slot_derivations\", {}).setdefault(\"conditions\", {})\n",
    "\n",
    "# Add the conditions object_derivation to the demography slot\n",
    "# participant_exposures_slot.setdefault(\"object_derivations\", [\n",
    "#     angina,\n",
    "#     # asthma,\n",
    "#     # copd,\n",
    "#     # diabetes,\n",
    "#     # hist_hrt_failure,\n",
    "#     # hist_my_inf,\n",
    "#     # hyperten,\n",
    "#     # pad,\n",
    "#     # slp_ap,\n",
    "#     # stroke,\n",
    "#     # stroke_isch_atk,\n",
    "# ])\n",
    "\n",
    "participant_exposures_slot.setdefault(\"object_derivations\", angina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bf4dbd-14f8-466e-828b-2d9ff79f24bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = TsvLoader(\"/sbgenomics/workspace/output/FHS_v31_c1/pht000395.tsv\")\n",
    "data_rows = data_loader.iter_instances()\n",
    "\n",
    "first_row = next(data_rows)\n",
    "cur_row = first_row\n",
    "\n",
    "transform_spec = participant_yaml\n",
    "\n",
    "input_data = cur_row\n",
    "\n",
    "# Create ObjectTransformer and apply transformation\n",
    "transformer = ObjectTransformer(unrestricted_eval=True)\n",
    "transformer.source_schemaview = SchemaView(source_schema)\n",
    "transformer.target_schemaview = SchemaView(target_schema)\n",
    "transformer.create_transformer_specification(transform_spec)\n",
    "\n",
    "result = transformer.map_object(input_data, source_type=\"pht000395\")\n",
    "\n",
    "print(result)\n",
    "print(\"Transformation Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de820310-8052-4865-bee4-4c48b647f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_spec = refactored_docs\n",
    "\n",
    "\n",
    "data_loader = TsvLoader(\"/sbgenomics/workspace/output/FHS_v31_c1/pht000009.tsv\")\n",
    "data_rows = data_loader.iter_instances()\n",
    "\n",
    "first_row = next(data_rows)\n",
    "cur_row = first_row\n",
    "\n",
    "input_data = cur_row\n",
    "\n",
    "# Create ObjectTransformer and apply transformation\n",
    "transformer = ObjectTransformer(unrestricted_eval=True)\n",
    "transformer.source_schemaview = SchemaView(source_schema)\n",
    "transformer.target_schemaview = SchemaView(target_schema)\n",
    "transformer.create_transformer_specification(transform_spec)\n",
    "\n",
    "result = transformer.map_object(input_data, source_type=\"pht000009\")\n",
    "\n",
    "print(result)\n",
    "print(\"Transformation Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186c7e83-ac94-43fb-872d-9fa7fa3b366c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c44f9e6-2a70-495f-bc23-92fcccc10ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn sequential class_derivations (malformed yaml) into list of class derivations.\n",
    "\n",
    "# Function to fix unquoted expr: text (malformed yaml)\n",
    "def quote_expr_values(yaml_text):\n",
    "    def replacer(match):\n",
    "        indent = match.group(1)\n",
    "        value = match.group(2).strip()\n",
    "\n",
    "        # Don't quote if already quoted OR looks like a quoted literal\n",
    "        if value.startswith('\"') or value.startswith(\"'\"):\n",
    "            return match.group(0)\n",
    "\n",
    "        # Don't quote if it's a simple scalar (e.g., a single variable)\n",
    "        if re.match(r'^[\\w{}\\s\\*\\+\\-/().]+$', value):\n",
    "            return f'{indent}expr: \"{value}\"'\n",
    "\n",
    "        # Otherwise, leave it as-is\n",
    "        return match.group(0)\n",
    "\n",
    "    pattern = re.compile(r'^(\\s*)expr:\\s+(.*)', re.MULTILINE)\n",
    "    return pattern.sub(replacer, yaml_text)\n",
    "\n",
    "# Read the raw YAML as text\n",
    "raw = Path(\"NHLBI-BDC-DMC-HV/priority_variables_transform/FHS/bdy_hgt_test.yaml\").read_text()\n",
    "# print(raw)\n",
    "\n",
    "quoted_fixed = quote_expr_values(raw)\n",
    "# Split while *keeping* 'class_derivations:' in each result, skip first line\n",
    "split_blocks = re.split(r'(?<=\\n)(?=^\\s*class_derivations:\\s*)', quoted_fixed, flags=re.MULTILINE)\n",
    "# print(split_blocks)\n",
    "\n",
    "# print(split_blocks)\n",
    "parsed_docs = [yaml.safe_load(doc) for doc in split_blocks]\n",
    "print(yaml.dump(parsed_docs))\n",
    "\n",
    "\n",
    "raw2 = Path(\"NHLBI-BDC-DMC-HV/priority_variables_transform/FHS/bdy_hgt_test2.yaml\").read_text()\n",
    "# print(raw2)\n",
    "\n",
    "# Split while *keeping* 'class_derivations:' in each result, skip first line\n",
    "split_blocks2 = re.split(r'(?<=\\n)(?=^\\s*class_derivations:\\s*)', raw2, flags=re.MULTILINE)\n",
    "# print(split_blocks2)\n",
    "print(split_blocks == split_blocks2)\n",
    "# quoted_fixed2 = quote_expr_values(raw2)\n",
    "# print(quoted_fixed2)\n",
    "parsed_docs2 = [yaml.safe_load(doc) for doc in split_blocks2]\n",
    "# print(yaml.dump(parsed_docs2))\n",
    "\n",
    "# parsed_docs = [yaml.safe_load(doc) for doc in quoted_fixed]\n",
    "\n",
    "# Use these if we can't guarantee the first class_derivation is first line of file.\n",
    "# # Split while *keeping* 'class_derivations:' in each result\n",
    "# split_blocks = re.split(r'(?=^\\s*class_derivations:\\s*)', raw, flags=re.MULTILINE)\n",
    "# # First block is likely empty or comments/header — skip it\n",
    "# blocks = [b for b in split_blocks[1:]]\n",
    "# parsed_docs = [yaml.safe_load(doc) for doc in blocks]\n",
    "\n",
    "# print(yaml.dump(quoted_fixed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdb0f83-db6c-42ca-a11f-66a01b5203f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn sequential class_derivations (malformed yaml) into list of class derivations.\n",
    "\n",
    "# Read the raw YAML as text\n",
    "raw = Path(\"NHLBI-BDC-DMC-HV/priority_variables_transform/FHS/apnea_hypop_index.yaml\").read_text()\n",
    "print(raw)\n",
    "\n",
    "# Split while *keeping* 'class_derivations:' in each result, skip first line\n",
    "split_blocks = re.split(r'(?<=\\n)(?=^\\s*class_derivations:\\s*)', raw, flags=re.MULTILINE)\n",
    "parsed_docs = [yaml.safe_load(doc) for doc in split_blocks]\n",
    "\n",
    "# Use these if we can't guarantee the first class_derivation is first line of file.\n",
    "# # Split while *keeping* 'class_derivations:' in each result\n",
    "# split_blocks = re.split(r'(?=^\\s*class_derivations:\\s*)', raw, flags=re.MULTILINE)\n",
    "# # First block is likely empty or comments/header — skip it\n",
    "# blocks = [b for b in split_blocks[1:]]\n",
    "# parsed_docs = [yaml.safe_load(doc) for doc in blocks]\n",
    "\n",
    "print(yaml.dump(parsed_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50907a8-faba-41aa-866d-4d793ad177b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "class LazySubjectDict(dict):\n",
    "    \"\"\"\n",
    "    Lazily loads per-pht data for a single subject on demand.\n",
    "    \"\"\"\n",
    "    def __init__(self, subject_id, data_dir):\n",
    "        super().__init__()\n",
    "        self.subject_id = subject_id\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self._cache = {}\n",
    "\n",
    "    def __getitem__(self, pht_id):\n",
    "        if pht_id in self._cache:\n",
    "            return self._cache[pht_id]\n",
    "\n",
    "        file_path = self.data_dir / f\"{pht_id}.tsv\"\n",
    "        if not file_path.exists():\n",
    "            raise KeyError(f\"No such file: {file_path}\")\n",
    "\n",
    "        with open(file_path, newline='') as f:\n",
    "            reader = csv.DictReader(f, delimiter=\"\\t\")\n",
    "            for row in reader:\n",
    "                if row.get(\"dbGaP_Subject_ID\") == self.subject_id:\n",
    "                    self._cache[pht_id] = row\n",
    "                    return row\n",
    "\n",
    "        raise KeyError(f\"Subject {self.subject_id} not found in {pht_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef9c58-9bce-420c-9248-7c0f9a64ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sv = SchemaView(\"/sbgenomics/workspace/output/Schema_FHS_v31_c1/schema-automator-data/Schema_FHS_v31_c1.yaml\")\n",
    "source_schema = source_sv.schema\n",
    "\n",
    "target_sv = SchemaView(\"NHLBI-BDC-DMC-HM/src/bdchm/schema/bdchm.yaml\")\n",
    "target_schema = target_sv.schema\n",
    "\n",
    "data_loader = TsvLoader(\"/sbgenomics/workspace/output/FHS_v31_c1/pht000030.tsv\")\n",
    "data_rows = data_loader.iter_instances()\n",
    "\n",
    "first_row = next(data_rows)\n",
    "cur_row = first_row\n",
    "\n",
    "var_dir = \"NHLBI-BDC-DMC-HV/priority_variables_transform/FHS/\"\n",
    "print(cur_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd0c51-db7e-455b-8a76-0e650078f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Person - top level class\n",
    "person_yaml = yaml.safe_load(\"\"\"\n",
    "class_derivations:\n",
    "  Person:\n",
    "    populated_from: pht000030\n",
    "    slot_derivations:\n",
    "      species:\n",
    "        expr: \"'Homo Sapiens'\"\n",
    "      identity:\n",
    "        populated_from: dbGaP_Subject_ID\n",
    "\"\"\")\n",
    "\n",
    "# # Dump to YAML\n",
    "# with open(var_dir + \"person\" + \".yaml\", \"w\") as f:\n",
    "#     yaml.dump(person_yaml, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d2f07c-b3ff-4c79-afc4-cb4c14d566c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participant - top level class for study data\n",
    "participant_yaml = yaml.safe_load(\"\"\"\n",
    "class_derivations:\n",
    "  Participant:\n",
    "    populated_from: pht000030\n",
    "    slot_derivations:\n",
    "      # associated_participant: \n",
    "      #   populated_from: phv00007675\n",
    "      identity:\n",
    "        populated_from: dbGaP_Subject_ID\n",
    "      member_of_research_study:\n",
    "        expr: \"'FHS'\"\n",
    "\"\"\")\n",
    "\n",
    "# # Dump to YAML\n",
    "# with open(var_dir + \"participant\" + \".yaml\", \"w\") as f:\n",
    "#     yaml.dump(participant_yaml, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8930fcd2-e946-456b-b50f-4daa8af5ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_spec = participant_yaml\n",
    "\n",
    "input_data = cur_row\n",
    "\n",
    "# Create ObjectTransformer and apply transformation\n",
    "transformer = ObjectTransformer(unrestricted_eval=True)\n",
    "transformer.source_schemaview = SchemaView(source_schema)\n",
    "transformer.target_schemaview = SchemaView(target_schema)\n",
    "transformer.create_transformer_specification(transform_spec)\n",
    "\n",
    "result = transformer.map_object(input_data, source_type=\"pht000030\")\n",
    "\n",
    "print(result)\n",
    "print(\"Transformation Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875a70eb-fe22-4b65-b53e-f250ff391f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the participants slot\n",
    "person_class = person_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Person\", {})\n",
    "person_participants_slot = person_class.setdefault(\"slot_derivations\", {}).setdefault(\"participants\", {})\n",
    "\n",
    "# Add the Participant object_derivation to the participants slot\n",
    "person_participants_slot.setdefault(\"object_derivations\", [ participant_yaml ])\n",
    "\n",
    "# print(yaml.dump(person_yaml, sort_keys=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209e7ddc-617e-4eee-b678-61ec490c1b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_spec = person_yaml\n",
    "\n",
    "input_data = cur_row\n",
    "\n",
    "# Create ObjectTransformer and apply transformation\n",
    "transformer = ObjectTransformer(unrestricted_eval=True)\n",
    "transformer.source_schemaview = SchemaView(source_schema)\n",
    "transformer.target_schemaview = SchemaView(target_schema)\n",
    "transformer.create_transformer_specification(transform_spec)\n",
    "\n",
    "result = transformer.map_object(input_data, source_type=\"pht000030\")\n",
    "\n",
    "print(result)\n",
    "print(\"Transformation Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5cb63d-1d40-450b-b4b8-d9454a45a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with one simple condition\n",
    "angina = yaml.safe_load(open(str(var_dir + \"angina\" + \".yaml\")))\n",
    "# print(yaml.dump(angina))\n",
    "\n",
    "# Get the conditions slot on Participants class\n",
    "participant_cls = participant_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Participant\", {})\n",
    "participant_exposures_slot = participant_cls.setdefault(\"slot_derivations\", {}).setdefault(\"conditions\", {})\n",
    "\n",
    "# Add the conditions object_derivation to the demography slot\n",
    "participant_exposures_slot.setdefault(\"object_derivations\", [\n",
    "    angina,\n",
    "    # asthma,\n",
    "    # copd,\n",
    "    # diabetes,\n",
    "    # hist_hrt_failure,\n",
    "    # hist_my_inf,\n",
    "    # hyperten,\n",
    "    # pad,\n",
    "    # slp_ap,\n",
    "    # stroke,\n",
    "    # stroke_isch_atk,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0a51fe-3ba9-474b-aae5-6d903e1b18d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yaml.dump(person_yaml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a1c2fc-e2a1-47cd-83a3-e6d257aff0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_spec = person_yaml\n",
    "\n",
    "data_loader = TsvLoader(\"/sbgenomics/workspace/output/FHS_v31_c1/pht000030.tsv\")\n",
    "data_rows = data_loader.iter_instances()\n",
    "\n",
    "first_row = next(data_rows)\n",
    "cur_row = first_row\n",
    "\n",
    "other_data_loader = TsvLoader(\"/sbgenomics/workspace/output/FHS_v31_c1/pht000395.tsv\")\n",
    "other_data_rows = other_data_loader.iter_instances()\n",
    "\n",
    "other_first_row = next(other_data_rows)\n",
    "other_cur_row = other_first_row\n",
    "\n",
    "input_data = {\n",
    "    \"pht000030\": cur_row,\n",
    "    \"pht000395\": other_cur_row\n",
    "}\n",
    "\n",
    "\n",
    "# Create ObjectTransformer and apply transformation\n",
    "transformer = ObjectTransformer(unrestricted_eval=True)\n",
    "transformer.source_schemaview = SchemaView(source_schema)\n",
    "transformer.target_schemaview = SchemaView(target_schema)\n",
    "transformer.create_transformer_specification(transform_spec)\n",
    "\n",
    "result = transformer.map_object(input_data, source_type=\"FHS\")\n",
    "\n",
    "print(result)\n",
    "print(\"Transformation Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d01721d-7268-4c24-9231-2707f85ba6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Condition class derivations\n",
    "angina = yaml.safe_load(open(str(var_dir + \"condition/\" + \"angina\" + \".yaml\")))\n",
    "asthma = yaml.safe_load(open(str(var_dir + \"condition/\" + \"asthma\" + \".yaml\")))\n",
    "copd = yaml.safe_load(open(str(var_dir + \"condition/\" + \"copd\" + \".yaml\")))\n",
    "diabetes = yaml.safe_load(open(str(var_dir + \"condition/\" + \"diabetes\" + \".yaml\")))\n",
    "hist_hrt_failure = yaml.safe_load(open(str(var_dir + \"condition/\" + \"hist_hrt_failure\" + \".yaml\")))\n",
    "hist_my_inf = yaml.safe_load(open(str(var_dir + \"condition/\" + \"hist_my_inf\" + \".yaml\")))\n",
    "hyperten = yaml.safe_load(open(str(var_dir + \"condition/\" + \"hyperten\" + \".yaml\")))\n",
    "pad = yaml.safe_load(open(str(var_dir + \"condition/\" + \"pad\" + \".yaml\")))\n",
    "slp_ap = yaml.safe_load(open(str(var_dir + \"condition/\" + \"slp_ap\" + \".yaml\")))\n",
    "stroke = yaml.safe_load(open(str(var_dir + \"condition/\" + \"stroke\" + \".yaml\")))\n",
    "stroke_isch_atk = yaml.safe_load(open(str(var_dir + \"condition/\" + \"stroke_isch_atk\" + \".yaml\")))\n",
    "\n",
    "# Get the conditions slot on Participants class\n",
    "participant_cls = participant_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Participant\", {})\n",
    "participant_exposures_slot = participant_cls.setdefault(\"slot_derivations\", {}).setdefault(\"conditions\", {})\n",
    "\n",
    "# Add the conditions object_derivation to the demography slot\n",
    "participant_exposures_slot.setdefault(\"object_derivations\", [\n",
    "    angina,\n",
    "    asthma,\n",
    "    copd,\n",
    "    diabetes,\n",
    "    hist_hrt_failure,\n",
    "    hist_my_inf,\n",
    "    hyperten,\n",
    "    pad,\n",
    "    slp_ap,\n",
    "    stroke,\n",
    "    stroke_isch_atk,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7015ab-d611-4c13-8cbf-dc2822def350",
   "metadata": {},
   "outputs": [],
   "source": [
    "demography_yaml = yaml.safe_load(\"\"\"\n",
    "class_derivations:\n",
    "  Demography:\n",
    "    populated_from: COPDGene\n",
    "    slot_derivations:\n",
    "      associated_participant:\n",
    "        populated_from: phv00159568\n",
    "      sex:\n",
    "        populated_from: phv00159571\n",
    "        value_mappings:\n",
    "          '1': OMOP:8507  # MALE\n",
    "          '2': OMOP:8532  # FEMALE\n",
    "      ethnicity:\n",
    "        populated_from: phv00159573\n",
    "        value_mappings:\n",
    "          '1': HISPANIC_OR_LATINO\n",
    "          '2': NOT_HISPANIC_OR_LATINO\n",
    "      race:\n",
    "        populated_from: phv00159572\n",
    "        value_mappings:\n",
    "          '1': OMOP:8527\n",
    "          '2': OMOP:8516\n",
    "          '3': OMOP:8515\n",
    "          '4': OMOP:8557\n",
    "          '5': OMOP:8657\n",
    "          '6': OMOP:45880900\n",
    "          '7': OMOP:8552\n",
    "\"\"\")\n",
    "\n",
    "# Dump to YAML\n",
    "with open(var_dir + \"demography\" + \".yaml\", \"w\") as f:\n",
    "    yaml.dump(demography_yaml, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0d3105-77d7-433b-a16a-5ddb36660e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the demography slot on Participants class\n",
    "participant_cls = participant_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Participant\", {})\n",
    "participant_demography_slot = participant_cls.setdefault(\"slot_derivations\", {}).setdefault(\"demography\", {})\n",
    "\n",
    "# Add the Demography object_derivation to the demography slot\n",
    "participant_demography_slot.setdefault(\"object_derivations\", [ demography_yaml ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed5ad67-f675-4164-ae89-ec6841e2d18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DrugExposure class derivations\n",
    "tak_betablk_resp = yaml.safe_load(open(str(var_dir + \"exposure/\" + \"tak_betablk_resp\" + \".yaml\")))\n",
    "tak_betablk = yaml.safe_load(open(str(var_dir + \"exposure/\" + \"tak_betablk\" + \".yaml\")))\n",
    "tak_adrenergics = yaml.safe_load(open(str(var_dir + \"exposure/\" + \"tak_adrenergics\" + \".yaml\")))\n",
    "tak_cort_steroid_resp = yaml.safe_load(open(str(var_dir + \"exposure/\" + \"tak_cort_steroid_resp\" + \".yaml\")))\n",
    "tak_cort_steroid_oral = yaml.safe_load(open(str(var_dir + \"exposure/\" + \"tak_cort_steroid_oral\" + \".yaml\")))\n",
    "tak_anabolic_steroid = yaml.safe_load(open(str(var_dir + \"exposure/\" + \"tak_anabolic_steroid\" + \".yaml\")))\n",
    "\n",
    "# Get the demography slot on Participants class\n",
    "participant_cls = participant_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Participant\", {})\n",
    "participant_exposures_slot = participant_cls.setdefault(\"slot_derivations\", {}).setdefault(\"exposures\", {})\n",
    "\n",
    "# Add the Demography object_derivation to the demography slot\n",
    "participant_exposures_slot.setdefault(\"object_derivations\", [\n",
    "    tak_betablk_resp,\n",
    "    tak_betablk,\n",
    "    tak_adrenergics,\n",
    "    tak_cort_steroid_resp,\n",
    "    tak_cort_steroid_oral,\n",
    "    tak_anabolic_steroid,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e7c770-d698-4a11-aaa4-0b371e8ea8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MeasurementObservation class derivations\n",
    "bdy_hgt = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"bdy_hgt\" + \".yaml\")))\n",
    "bdy_wgt = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"bdy_wgt\" + \".yaml\")))\n",
    "bmi = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"bmi\" + \".yaml\")))\n",
    "bp_diastolic = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"bp_diastolic\" + \".yaml\")))\n",
    "bp_systolic = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"bp_systolic\" + \".yaml\")))\n",
    "fev1 = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"fev1\" + \".yaml\")))\n",
    "fev1_fvc = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"fev1_fvc\" + \".yaml\")))\n",
    "fvc = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"fvc\" + \".yaml\")))\n",
    "hrt_rt = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"hrt_rt\" + \".yaml\")))\n",
    "spo2 = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"spo2\" + \".yaml\")))\n",
    "\n",
    "# Get the demography slot on Participants class\n",
    "participant_cls = participant_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Participant\", {})\n",
    "participant_exposures_slot = participant_cls.setdefault(\"slot_derivations\", {}).setdefault(\"exposures\", {})\n",
    "\n",
    "# Add the Demography object_derivation to the demography slot\n",
    "participant_exposures_slot.setdefault(\"object_derivations\", [\n",
    "    bdy_hgt,\n",
    "    tak_betablk,\n",
    "    tak_adrenergics,\n",
    "    tak_cort_steroid_resp,\n",
    "    tak_cort_steroid_oral,\n",
    "    tak_anabolic_steroid,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dd1d49-f23d-4992-a0bd-f93241a510b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_yaml = yaml.safe_load(\"\"\"\n",
    "class_derivations:\n",
    "  Observation:\n",
    "    populated_from: COPDGene\n",
    "    slot_derivations:\n",
    "      associated_participant:\n",
    "        populated_from: phv00159568\n",
    "      observation_type:\n",
    "        expr: \"'OMOP:4282779'\"  # Cigarette smoking status\n",
    "      value_enum:\n",
    "        expr: \"'OMOP:40766945' if {phv00159749} == 1 else 'OMOP:45883458' if {phv00159747} == 1 else 'OMOP:45883537'\"\n",
    "\"\"\")\n",
    "\n",
    "# Dump to YAML\n",
    "with open(var_dir + \"observation\" + \".yaml\", \"w\") as f:\n",
    "    yaml.dump(observation_yaml, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ae05d-a027-447a-9e3c-216ed11e308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the observations slot on Participants class\n",
    "participant_cls = participant_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Participant\", {})\n",
    "participant_observations_slot = participant_cls.setdefault(\"slot_derivations\", {}).setdefault(\"observations\", {})\n",
    "\n",
    "# Add the Demography object_derivation to the demography slot\n",
    "participant_observations_slot.setdefault(\"object_derivations\", [ observation_yaml ])\n",
    "\n",
    "# print(yaml.dump(person_yaml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3705b06-a868-411d-91fe-273c2590a378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_cor_angio\n",
    "hist_cor_angio = yaml.safe_load(\"\"\"\n",
    "class_derivations:\n",
    "  Procedure:\n",
    "    populated_from: COPDGene\n",
    "    slot_derivations:\n",
    "      associated_participant:\n",
    "        populated_from: phv00159568\n",
    "      procedure_concept:\n",
    "        expr: \"'OMOP:4184832'\"  # Coronary angioplasty\n",
    "      procedure_status:\n",
    "        populated_from: phv00159632\n",
    "        value_mappings:\n",
    "          '0': ABSENT\n",
    "          '1': PRESENT\n",
    "\"\"\")\n",
    "\n",
    "# Dump to YAML\n",
    "with open(var_dir + \"procedure/\" + \"hist_cor_angio\" + \".yaml\", \"w\") as f:\n",
    "    yaml.dump(hist_cor_angio, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f881446b-f8a6-4948-a740-8f4c32f6052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_spec = hist_cor_angio\n",
    "\n",
    "input_data = cur_row\n",
    "\n",
    "# Create ObjectTransformer and apply transformation\n",
    "transformer = ObjectTransformer(unrestricted_eval=True)\n",
    "transformer.source_schemaview = SchemaView(source_schema)\n",
    "transformer.target_schemaview = SchemaView(target_schema)\n",
    "transformer.create_transformer_specification(transform_spec)\n",
    "\n",
    "result = transformer.map_object(input_data, source_type=\"COPDGene\")\n",
    "\n",
    "print(result)\n",
    "print(\"Transformation Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabe767f-d4c7-4c5a-8a24-31b846b744b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_cor_bypg\n",
    "hist_cor_bypg = yaml.safe_load(\"\"\"\n",
    "class_derivations:\n",
    "  Procedure:\n",
    "    populated_from: COPDGene\n",
    "    slot_derivations:\n",
    "      associated_participant:\n",
    "        populated_from: phv00159568\n",
    "      procedure_concept:\n",
    "        expr: \"'OMOP:4336464'\"  #coronary bypass graft\n",
    "      procedure_status:\n",
    "        populated_from: phv00159631\n",
    "        value_mappings:\n",
    "          '0': ABSENT\n",
    "          '1': PRESENT\n",
    "\"\"\")\n",
    "\n",
    "# Dump to YAML\n",
    "with open(var_dir + \"procedure/\" + \"hist_cor_bypg\" + \".yaml\", \"w\") as f:\n",
    "    yaml.dump(hist_cor_bypg, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05f167b-0aa3-4838-93fd-d7c1647f8d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the observations slot on Participants class\n",
    "participant_cls = participant_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Participant\", {})\n",
    "participant_procedures_slot = participant_cls.setdefault(\"slot_derivations\", {}).setdefault(\"procedures\", {})\n",
    "\n",
    "# Add the Demography object_derivation to the demography slot\n",
    "participant_procedures_slot.setdefault(\"object_derivations\", [ hist_cor_angio, hist_cor_bypg ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f40868-b270-4ceb-95d3-69e8d998d950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edu_lvl\n",
    "edu_lvl = yaml.safe_load(\"\"\"\n",
    "class_derivations:\n",
    "  SdohObservation:\n",
    "    populated_from: COPDGene\n",
    "    slot_derivations:\n",
    "      associated_participant:\n",
    "        populated_from: phv00159568\n",
    "      category:\n",
    "        expr: \"'EDUCATIONAL_ATTAINMENT'\"\n",
    "      value_enum:\n",
    "        populated_from: phv00159773\n",
    "        value_mappings:\n",
    "          '1': 8TH_GRADE_OR_LESS\n",
    "          '2': HIGH_SCHOOL_NO_DIPLOMA\n",
    "          '3': HIGH_SCHOOL_GRADUATE_GED\n",
    "          '4': SOME_COLLEGE_OR_TECH_NO_DEGREE\n",
    "          '5': COLLEGE_OR_TECH_WITH_DEGREE\n",
    "          '6': MASTERS_OR_DOCTORAL_DEGREE\n",
    "\"\"\")\n",
    "\n",
    "# Dump to YAML\n",
    "with open(var_dir + \"sdoh_observation/\" + \"edu_lvl\" + \".yaml\", \"w\") as f:\n",
    "    yaml.dump(edu_lvl, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee7fba1-14a5-4250-8a7f-fe8fb5859d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the observations slot on Participants class\n",
    "participant_cls = participant_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Participant\", {})\n",
    "participant_sdoh_observations_slot = participant_cls.setdefault(\"slot_derivations\", {}).setdefault(\"sdoh_observations\", {})\n",
    "\n",
    "# Add the Demography object_derivation to the demography slot\n",
    "participant_sdoh_observations_slot.setdefault(\"object_derivations\", [ edu_lvl ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6070261a-440a-40ec-ad40-143c4cf59208",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_spec = person_yaml\n",
    "\n",
    "input_data = cur_row\n",
    "\n",
    "# Create ObjectTransformer and apply transformation\n",
    "transformer = ObjectTransformer(unrestricted_eval=True)\n",
    "transformer.source_schemaview = SchemaView(source_schema)\n",
    "transformer.target_schemaview = SchemaView(target_schema)\n",
    "transformer.create_transformer_specification(transform_spec)\n",
    "\n",
    "# Transform all rows\n",
    "output_data = []\n",
    "for row in data_rows:\n",
    "    result = transformer.map_object(row, source_type=\"COPDGene\")\n",
    "    if result:  # Avoid None or empty dicts\n",
    "        output_data.append(result)\n",
    "\n",
    "# Final wrapped structure (key should match the collection slot, or be schema-compatible)\n",
    "wrapped_output = {\n",
    "    \"persons\": output_data\n",
    "}\n",
    "\n",
    "# Dump to YAML\n",
    "with open(\"transformed_person_data_DS_CS.yaml\", \"w\") as f:\n",
    "    yaml.dump(wrapped_output, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "print(\"Transformation Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2751e283-9235-4423-b15e-d1922c612dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump final Person class to YAML\n",
    "with open(var_dir + \"person\" + \".yaml\", \"w\") as f:\n",
    "    yaml.dump(person_yaml, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5851b15-1e24-46cb-b95e-b7d50f656c44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dm-bip)",
   "language": "python",
   "name": "dm-bip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
