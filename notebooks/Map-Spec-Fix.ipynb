{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c146cdd-f168-42aa-9a96-b7695537385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean a file by removing problematic variables by name\n",
    "import csv\n",
    "\n",
    "input_file = \"/sbgenomics/workspace/output/CHS_cleaned/pht001492.tsv\"\n",
    "output_file = \"/sbgenomics/workspace/output/CHS_cleaned/CHS_v7_c1/pht001492.tsv\"\n",
    "columns_to_drop = [\"phv00107747\", \"phv00107748\", \"phv00107749\", \"phv00108147\", \"phv00108148\", \"phv00108149\", \"phv00108150\"] \n",
    "\n",
    "# input_file = \"/sbgenomics/workspace/output/CHS_cleaned/pht001494.tsv\"\n",
    "# output_file = \"/sbgenomics/workspace/output/CHS_cleaned/CHS_v7_c1/pht001494.tsv\"\n",
    "# columns_to_drop = [\"phv00109384\", ] \n",
    "\n",
    "with open(input_file, newline=\"\", encoding=\"utf-8\") as infile:\n",
    "    reader = csv.DictReader(infile, delimiter=\"\\t\")\n",
    "    fieldnames = [fn for fn in reader.fieldnames if fn not in columns_to_drop]\n",
    "\n",
    "    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames, delimiter=\"\\t\")\n",
    "        writer.writeheader()\n",
    "        for row in reader:\n",
    "            writer.writerow({k: v for k, v in row.items() if k in fieldnames})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6739dc-7468-44b2-b00c-3ca089958005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import subprocess\n",
    "from typing import Optional\n",
    "import yaml\n",
    "\n",
    "from linkml.validator.loaders import TsvLoader\n",
    "from linkml.utils.schema_builder import SchemaBuilder\n",
    "\n",
    "from linkml_runtime.linkml_model import SlotDefinition\n",
    "from linkml_runtime import SchemaView\n",
    "\n",
    "from linkml_map.session import Session\n",
    "from linkml_map.transformer.object_transformer import ObjectTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0426938-49b9-401f-98cb-660f4c2a4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_misindented_value_mappings(yaml_text):\n",
    "    lines = yaml_text.splitlines()\n",
    "    fixed = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        fixed.append(line)\n",
    "        if re.match(r'^\\s+populated_from:\\s+\\S+', line):\n",
    "            pf_indent = len(line) - len(line.lstrip())\n",
    "            # Peek ahead to see if value_mappings is wrongly indented\n",
    "            if i + 1 < len(lines) and lines[i + 1].lstrip().startswith(\"value_mappings:\"):\n",
    "                vm_line = lines[i + 1]\n",
    "                vm_indent = len(vm_line) - len(vm_line.lstrip())\n",
    "                if vm_indent > pf_indent:\n",
    "                    # Dedent value_mappings\n",
    "                    fixed.append(\" \" * pf_indent + vm_line.lstrip())\n",
    "                    i += 1\n",
    "                    # Dedent any following lines more indented than vm_indent\n",
    "                    while i + 1 < len(lines):\n",
    "                        peek = lines[i + 1]\n",
    "                        peek_indent = len(peek) - len(peek.lstrip())\n",
    "                        if peek_indent > vm_indent:\n",
    "                            i += 1\n",
    "                            fixed.append(\" \" * (pf_indent + 2) + peek.lstrip())\n",
    "                        else:\n",
    "                            break\n",
    "        i += 1\n",
    "    return \"\\n\".join(fixed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ef28a-ed34-4c5e-acf3-59a9ad410732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_nested_expr_under_populated_from(yaml_text: str) -> str:\n",
    "    lines = yaml_text.splitlines()\n",
    "    out_lines = []\n",
    "    i = 0\n",
    "\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "\n",
    "        if line.lstrip().startswith(\"populated_from:\"):\n",
    "            indent = len(line) - len(line.lstrip())\n",
    "            next_line = lines[i + 1] if i + 1 < len(lines) else \"\"\n",
    "\n",
    "            if next_line.lstrip().startswith(\"expr:\"):\n",
    "                # Rewrite: replace populated_from + expr with dedented expr\n",
    "                out_lines.append(\" \" * indent + next_line.lstrip())\n",
    "                i += 2\n",
    "\n",
    "                # Append any deeper-indented lines\n",
    "                while i < len(lines):\n",
    "                    peek = lines[i]\n",
    "                    if len(peek) - len(peek.lstrip()) > indent:\n",
    "                        out_lines.append(\" \" * (indent + 2) + peek.lstrip())\n",
    "                        i += 1\n",
    "                    else:\n",
    "                        break\n",
    "                continue\n",
    "\n",
    "        out_lines.append(line)\n",
    "        i += 1\n",
    "\n",
    "    return \"\\n\".join(out_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72020212-f38e-472f-a427-d881278d4248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_phv_brackets(expr: str) -> str:\n",
    "    expr = re.sub(r'(?<![{])\\b(phv\\d{8})', r'{\\1', expr)\n",
    "    expr = re.sub(r'(phv\\d{8})\\b(?![}])', r'\\1}', expr)\n",
    "    return expr\n",
    "\n",
    "def quote_curies(expr: str) -> str:\n",
    "    return re.sub(r'\\b([A-Z]+:\\d+)\\b', r'\"\\1\"', expr)\n",
    "\n",
    "def strip_outer_quotes(expr: str) -> str:\n",
    "    expr = expr.strip()\n",
    "    expr = re.sub(r\"^['\\\"]+\", \"\", expr)\n",
    "    expr = re.sub(r\"['\\\"]+$\", \"\", expr)\n",
    "    expr = expr.strip()\n",
    "    return expr\n",
    "\n",
    "def normalize_expr_string(expr: str) -> str:\n",
    "    expr = strip_outer_quotes(expr)\n",
    "    expr = re.sub(r'\\s+#.*$', '', expr)\n",
    "    expr = fix_phv_brackets(expr)\n",
    "    expr = quote_curies(expr)\n",
    "    expr = expr.replace('\"', '\\\\\"')  # Escape internal quotes\n",
    "    return f\"\\\"{expr}\\\"\"\n",
    "\n",
    "def fix_expr_strings(pre_yaml_text: str) -> str:\n",
    "    lines = pre_yaml_text.splitlines()\n",
    "    out_lines = []\n",
    "    i = 0\n",
    "\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        stripped = line.lstrip()\n",
    "        indent = len(line) - len(stripped)\n",
    "\n",
    "        if stripped.startswith(\"expr:\"):\n",
    "            expr_val = stripped[len(\"expr:\"):].lstrip()\n",
    "            i += 1\n",
    "            # Collect multi-line expression if indented more\n",
    "            while i < len(lines):\n",
    "                next_line = lines[i]\n",
    "                next_indent = len(next_line) - len(next_line.lstrip())\n",
    "                if next_indent > indent:\n",
    "                    expr_val += \"\" + next_line.strip()\n",
    "                    i += 1\n",
    "                else:\n",
    "                    break\n",
    "            # Normalize and re-quote\n",
    "            quoted_expr = normalize_expr_string(expr_val)\n",
    "            out_lines.append(\" \" * indent + f\"expr: {quoted_expr}\")\n",
    "        else:\n",
    "            out_lines.append(line)\n",
    "            i += 1\n",
    "\n",
    "    return \"\\n\".join(out_lines)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b3a53f-db72-4818-8377-50863b79ec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_quantity_subslots(slot_derivs, doc_index, parent_slot_name, populated_from, known_subslots):\n",
    "    quantity_subslots = {}\n",
    "\n",
    "    # 1. Pull nested subslots under e.g. range_low: { value_decimal: ... }\n",
    "    nested = slot_derivs.pop(parent_slot_name, {}) if isinstance(slot_derivs.get(parent_slot_name), dict) else {}\n",
    "\n",
    "    # 2. Scan for both nested and top-level flat entries\n",
    "    for subkey in known_subslots:\n",
    "        # Support flat key: e.g., value_quantity.unit\n",
    "        flat_key = f\"{parent_slot_name}.{subkey}\"\n",
    "\n",
    "        entry = (\n",
    "            nested.pop(subkey, None)\n",
    "            or slot_derivs.pop(flat_key, None)\n",
    "            or slot_derivs.pop(subkey, None)  # e.g., value_decimal defined at top-level\n",
    "        )\n",
    "\n",
    "        if entry:\n",
    "            if isinstance(entry, dict):\n",
    "                pf = entry.get(\"populated_from\")\n",
    "                expr = entry.get(\"expr\")\n",
    "                value = entry.get(\"value\")\n",
    "\n",
    "                if pf and isinstance(pf, dict) and \"expr\" in pf:\n",
    "                    quantity_subslots[subkey] = {\"expr\": pf[\"expr\"]}\n",
    "                elif expr:\n",
    "                    quantity_subslots[subkey] = {\"expr\": expr}\n",
    "                elif value:\n",
    "                    quantity_subslots[subkey] = {\"value\": value}\n",
    "                elif pf is None:\n",
    "                    raise ValueError(f\"[Doc {doc_index}] `{subkey}` in `{parent_slot_name}` has empty `populated_from:` and no `expr:`\")\n",
    "                elif isinstance(pf, str):\n",
    "                    quantity_subslots[subkey] = {\"populated_from\": pf}\n",
    "                else:\n",
    "                    raise ValueError(f\"[Doc {doc_index}] Malformed `{subkey}` in `{parent_slot_name}`: {entry}\")\n",
    "            else:\n",
    "                raise ValueError(f\"[Doc {doc_index}] Unexpected format for `{subkey}` in `{parent_slot_name}`: {entry}\")\n",
    "\n",
    "    if quantity_subslots:\n",
    "        return {\n",
    "            \"object_derivations\": [{\n",
    "                \"class_derivations\": {\n",
    "                    \"Quantity\": {\n",
    "                        \"populated_from\": populated_from,\n",
    "                        \"slot_derivations\": quantity_subslots\n",
    "                    }\n",
    "                }\n",
    "            }]\n",
    "        }\n",
    "\n",
    "    return None\n",
    "\n",
    "def refactor_value_quantity(documents):\n",
    "    updated_docs = []\n",
    "\n",
    "    quantity_subslots = [\"value_decimal\", \"value_concept\", \"value_integer\", \"unit\"]\n",
    "\n",
    "    for doc_index, doc in enumerate(documents):\n",
    "        cd = doc.get(\"class_derivations\", {})\n",
    "        for cls_name, cls_info in cd.items():\n",
    "            slot_derivs = cls_info.get(\"slot_derivations\", {})\n",
    "            populated_from = cls_info.get(\"populated_from\")\n",
    "\n",
    "            # Apply to each target \"container\" slot\n",
    "            for target_slot in [\"value_quantity\", \"range_low\", \"range_high\"]:\n",
    "                result = extract_quantity_subslots(\n",
    "                    slot_derivs,\n",
    "                    doc_index,\n",
    "                    target_slot,\n",
    "                    populated_from,\n",
    "                    quantity_subslots\n",
    "                )\n",
    "                if result:\n",
    "                    slot_derivs[target_slot] = result\n",
    "\n",
    "        updated_docs.append(doc)\n",
    "\n",
    "    return updated_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb6bbd4-7734-43ee-8504-8711116f9fe5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXPR_PATTERN = re.compile(r'\\b(case)\\b|[()+*<>]|(?<!\\w)[/-](?=\\w)')\n",
    "# EXPR_PATTERN = re.compile(r'\\bcase\\b|[()+*<>]|(?<!\\w)[/-](?=\\w)|(?<=\\w)\\s*[/-]\\s*(?=\\w)')\n",
    "PHV_PATTERN = re.compile(r'\\{phv\\d{8}\\}')\n",
    "NUMERIC_ARITH_PATTERN = re.compile(r'\\b\\d+(\\.\\d+)?\\s*[-+*/]\\s*\\d+(\\.\\d+)?\\b')\n",
    "KNOWN_CONSTANTS = {\"{#}/wk\", \"10*6/uL\", \"10*3/uL\", \"g/dL\", \"mg/L\", \"mg/g\", \"U/L\", \"[IU]/L\", \"1/hr\", \"mg/dL\", \"MESA CLASSIC EXAM 2-3\"}\n",
    "SIMPLE_STRING_FIELDS = { \"method_type\", \"observation_type\", \"vital_status\"}\n",
    "\n",
    "def is_const_expr(expr: str) -> bool:\n",
    "    expr = expr.strip().strip(\"'\\\"\")\n",
    "    if not expr:\n",
    "        return False\n",
    "    if expr in KNOWN_CONSTANTS:\n",
    "        return True\n",
    "    if PHV_PATTERN.search(expr):\n",
    "        return False\n",
    "    if NUMERIC_ARITH_PATTERN.search(expr):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def const_expr_to_value_in_slot(slot_name: str, slot_deriv: dict | str) -> dict:\n",
    "    if isinstance(slot_deriv, str) and slot_name in SIMPLE_STRING_FIELDS:\n",
    "        # print(f\"üõ† Fixing simple string slot: {slot_name} ‚Üí value: {slot_deriv}\")\n",
    "        return {\"value\": slot_deriv.strip(\"'\\\"\"), \"range\": \"string\"}\n",
    "\n",
    "    if isinstance(slot_deriv, dict):\n",
    "        expr = slot_deriv.get(\"expr\")\n",
    "\n",
    "        if isinstance(expr, str):\n",
    "            if expr.strip().startswith(\"case(\") and \"case(\" in expr.split(\"case(\", 1)[1]:\n",
    "                print(f\"‚ùå Found malformed case expression: {expr}\")\n",
    "            if is_const_expr(expr):\n",
    "                slot_deriv[\"value\"] = expr.strip(\"'\\\"\")\n",
    "                slot_deriv.pop(\"expr\", None)\n",
    "                slot_deriv.setdefault(\"range\", \"string\")\n",
    "\n",
    "    return slot_deriv\n",
    "\n",
    "def const_expr_to_value_in_class(class_deriv: dict) -> None:\n",
    "    slot_derivs = class_deriv.get(\"slot_derivations\", {})\n",
    "    # for slot_deriv in slot_derivs.values():\n",
    "    #     const_expr_to_value_in_slot(slot_deriv)\n",
    "    for slot_name, slot_deriv in list(slot_derivs.items()):\n",
    "        slot_derivs[slot_name] = const_expr_to_value_in_slot(slot_name, slot_deriv)\n",
    "        if isinstance(slot_deriv, dict):\n",
    "            for obj in slot_deriv.get(\"object_derivations\", []):\n",
    "                if isinstance(obj, dict):\n",
    "                    class_derivs = obj.get(\"class_derivations\", {})\n",
    "                    for inner_class in class_derivs.values():\n",
    "                        if isinstance(inner_class, dict):\n",
    "                            const_expr_to_value_in_class(inner_class)\n",
    "\n",
    "\n",
    "\n",
    "def const_expr_to_value(parsed_docs: list[dict]) -> list[dict]:\n",
    "    for doc in parsed_docs:\n",
    "        for class_deriv in doc.get(\"class_derivations\", {}).values():\n",
    "            const_expr_to_value_in_class(class_deriv)\n",
    "    return parsed_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cf4540-06ce-498f-a45b-3eb7e3e4ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_populated_from_with_pht(documents, phv_to_pht):\n",
    "    def find_first_phv_in_slot(slot_derivations):\n",
    "        for slot_value in slot_derivations.values():\n",
    "            if isinstance(slot_value, dict):\n",
    "                pf = slot_value.get(\"populated_from\")\n",
    "                expr = slot_value.get(\"expr\")\n",
    "\n",
    "                if isinstance(pf, str) and pf.startswith(\"phv\"):\n",
    "                    return pf\n",
    "                if isinstance(expr, str):\n",
    "                    match = re.search(r\"(phv\\d{8})\", expr)\n",
    "                    if match:\n",
    "                        return match.group(1)\n",
    "        return None\n",
    "\n",
    "    def update_class_derivations(cls_derivations, doc_index, context=\"root\", parent_pht=None):\n",
    "        for cls_name, cls_info in cls_derivations.items():\n",
    "            slot_derivs = cls_info.get(\"slot_derivations\", {})\n",
    "            pf = cls_info.get(\"populated_from\")\n",
    "\n",
    "            if pf == \"FHS\":\n",
    "                phv = find_first_phv_in_slot(slot_derivs)\n",
    "                if phv and phv in phv_to_pht:\n",
    "                    new_pf = phv_to_pht[phv]\n",
    "                    cls_info[\"populated_from\"] = new_pf\n",
    "                    parent_pht = new_pf  # propagate to children\n",
    "                    # print(f\"‚úÖ Updated {context}.{cls_name} populated_from: {phv} -> {new_pf}\")\n",
    "                elif parent_pht:\n",
    "                    cls_info[\"populated_from\"] = parent_pht\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Warning: No matching phv for {context}.{cls_name} in doc {doc_index}\")\n",
    "\n",
    "            # Recurse into nested object_derivations\n",
    "            for slot_name, slot_value in slot_derivs.items():\n",
    "                if isinstance(slot_value, dict) and \"object_derivations\" in slot_value:\n",
    "                    for obj in slot_value[\"object_derivations\"]:\n",
    "                        inner_cls_derivs = obj.get(\"class_derivations\")\n",
    "                        if inner_cls_derivs:\n",
    "                            update_class_derivations(inner_cls_derivs, doc_index, context=f\"{context}.{cls_name}.{slot_name}\", parent_pht=parent_pht)\n",
    "\n",
    "    for doc_index, doc in enumerate(documents):\n",
    "        top_cd = doc.get(\"class_derivations\", {})\n",
    "        update_class_derivations(top_cd, doc_index)\n",
    "\n",
    "    return documents\n",
    "\n",
    "def load_phv_to_pht_map(file_path):\n",
    "    with open(file_path) as f:\n",
    "        return dict(line.strip().split(\": \") for line in f if line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c9241f-2ccc-41a9-b96f-30b50d526b46",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_inline_comments(parsed_docs: list[dict]) -> list[dict]:\n",
    "    def extract_comment_from_value(val: str) -> tuple[str, Optional[str]]:\n",
    "        if \"#\" in val:\n",
    "            main, comment = val.split(\"#\", 1)\n",
    "            return main.strip(), comment.strip()\n",
    "        return val, None\n",
    "\n",
    "    def fix_slot(slot: dict):\n",
    "        if not isinstance(slot, dict):\n",
    "            return\n",
    "        for field in (\"value\", \"expr\"):\n",
    "            val = slot.get(field)\n",
    "            if isinstance(val, str) and \"#\" in val:\n",
    "                clean_val, comment = extract_comment_from_value(val)\n",
    "                slot[field] = clean_val\n",
    "                if comment:\n",
    "                    slot.setdefault(\"comments\", []).append(comment)\n",
    "\n",
    "    def recurse_class(class_deriv: dict):\n",
    "        for slot_deriv in class_deriv.get(\"slot_derivations\", {}).values():\n",
    "            fix_slot(slot_deriv)\n",
    "            if not isinstance(slot_deriv, dict):\n",
    "              print(f\"‚ö†Ô∏è Warning: No matching slot_deriv\\n {slot_deriv}\\n for\\n {class_deriv}\\n is not a dict\")\n",
    "              continue\n",
    "            for obj in slot_deriv.get(\"object_derivations\", []):\n",
    "                if isinstance(obj, dict):\n",
    "                    recurse_class(obj)\n",
    "\n",
    "    for doc in parsed_docs:\n",
    "        for class_deriv in doc.get(\"class_derivations\", {}).values():\n",
    "            recurse_class(class_deriv)\n",
    "\n",
    "    return parsed_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8374c43-9345-4fe0-82d6-80dc0f73c158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spec_dir = Path(\"/sbgenomics/workspace/NHLBI-BDC-DMC-HV/priority_variables_transform/CHS\")\n",
    "# output_dir = Path(\"/sbgenomics/workspace/NHLBI-BDC-DMC-HV/priority_variables_transform/CHS-ingest\")\n",
    "\n",
    "# spec_dir = Path(\"/sbgenomics/workspace/NHLBI-BDC-DMC-HV/priority_variables_transform/HCHS\")\n",
    "# output_dir = Path(\"/sbgenomics/workspace/NHLBI-BDC-DMC-HV/priority_variables_transform/HCHS-ingest\")\n",
    "\n",
    "spec_dir = Path(\"/sbgenomics/workspace/NHLBI-BDC-DMC-HV/priority_variables_transform/MESA/\")\n",
    "output_dir = Path(\"/sbgenomics/workspace/NHLBI-BDC-DMC-HV/priority_variables_transform/MESA-ingest\")\n",
    "\n",
    "SKIP_BASES = {\"bld_pressure\", \"pr_qrs_qt\", } \n",
    "# RUN_BASES = {\"chloride_bld\", }\n",
    "\n",
    "# Files with issues\n",
    "#   tak_betablk  -- enum derivation\n",
    "#   bld_pressure  -- MeasurementObservationSet\n",
    "\n",
    "for yaml_file in spec_dir.glob(\"*.yaml\"):\n",
    "    base = yaml_file.stem  # Strip .yaml\n",
    "    output_file = f\"{output_dir}/{base}.yaml\"\n",
    "    \n",
    "    # if base not in RUN_BASES:\n",
    "    #     # print(f\"‚è≠Ô∏è Skipping {base}\")\n",
    "    #     continue\n",
    "    \n",
    "    if base in SKIP_BASES:\n",
    "        print(f\"‚è≠Ô∏è Skipping {base}\")\n",
    "        continue\n",
    "    \n",
    "    print(base)\n",
    "    raw = \"\\n\".join(line.rstrip() for line in yaml_file.read_text().splitlines())\n",
    "    pre_yaml = \"\\n\".join(line.rstrip() for line in raw.splitlines())\n",
    "    pre_yaml = re.sub(r'^(\\s*[^#:\\n]+?):(?=\\S)', r'\\1: ', pre_yaml, flags=re.MULTILINE)\n",
    "    pre_yaml = re.sub(r'^(\\s*)populated from:(.*)$', r'\\1populated_from:\\2', pre_yaml, flags=re.MULTILINE)\n",
    "    pre_yaml = fix_misindented_value_mappings(pre_yaml)\n",
    "    pre_yaml = fix_nested_expr_under_populated_from(pre_yaml)\n",
    "    pre_yaml = fix_expr_strings(pre_yaml)\n",
    "\n",
    "    # Split into list of class derivations if not already a YAML list\n",
    "    if pre_yaml.lstrip().startswith(\"- class_derivations:\"):\n",
    "        parsed_yaml = yaml.safe_load(pre_yaml)\n",
    "    else:\n",
    "        pre_yaml_parts = re.split(r'(?<=\\n)(?=^class_derivations:\\s*)', pre_yaml, flags=re.MULTILINE)\n",
    "        parsed_yaml = [yaml.safe_load(doc) for doc in pre_yaml_parts]\n",
    "\n",
    "    # parsed_yaml = refactor_value_quantity(parsed_yaml)\n",
    "    parsed_yaml = const_expr_to_value(parsed_yaml)\n",
    "    \n",
    "    parsed_yaml = extract_inline_comments(parsed_yaml)\n",
    "    \n",
    "    # Dump to YAML\n",
    "    with open(output_file, \"w\") as f:\n",
    "        yaml.dump(parsed_yaml, f, sort_keys=False, allow_unicode=True)\n",
    "print(\"Success!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3fc909-c089-4bf3-aa9c-6de95b499b1a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(yaml.dump(parsed_yaml[0]))\n",
    "print(pre_yaml)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dm-bip)",
   "language": "python",
   "name": "dm-bip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
