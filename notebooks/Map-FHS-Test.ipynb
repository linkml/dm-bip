{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf6739dc-7468-44b2-b00c-3ca089958005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import subprocess\n",
    "import yaml\n",
    "\n",
    "from linkml.validator.loaders import TsvLoader\n",
    "from linkml.utils.schema_builder import SchemaBuilder\n",
    "\n",
    "from linkml_runtime.linkml_model import SlotDefinition\n",
    "from linkml_runtime import SchemaView\n",
    "\n",
    "from linkml_map.session import Session\n",
    "from linkml_map.transformer.object_transformer import ObjectTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dc21578-0c34-4e2a-b7ed-ec6df8b24359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix malformed yaml\n",
    "def quote_expr_values(yaml_text):\n",
    "    def replacer(match):\n",
    "        indent = match.group(1)\n",
    "        value = match.group(2).strip()\n",
    "\n",
    "        if value.startswith('\"') or value.startswith(\"'\"):\n",
    "            return match.group(0)\n",
    "        if re.match(r'^[\\w{}\\s\\*\\+\\-/().]+$', value):\n",
    "            return f'{indent}expr: \"{value}\"'\n",
    "        return match.group(0)\n",
    "\n",
    "    pattern = re.compile(r'^(\\s*)expr:\\s+(.*)', re.MULTILINE)\n",
    "    return pattern.sub(replacer, yaml_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11e2e25a-ed25-4c47-8af4-e13f55365537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix malformed yaml\n",
    "def quote_expr_values(yaml_text):\n",
    "    def replacer(match):\n",
    "        indent = match.group(1)\n",
    "        value = match.group(2).strip()\n",
    "        \n",
    "        if value.startswith('\"') or value.startswith(\"'\"):\n",
    "            if \"#\" in value and (value.endswith('\"') or value.endswith(\"'\")):\n",
    "                quote_char = value[0]\n",
    "                strip_comment = value[1:-1].split('#')[0].strip()\n",
    "                return f'{indent}expr: {quote_char}{strip_comment}{quote_char}'\n",
    "            return match.group(0)\n",
    "        \n",
    "        value = value.split('#')[0].strip()\n",
    "        if re.match(r'^[\\w{}\\s\\*\\+\\-/().]+$', value):\n",
    "            return f'{indent}expr: \"{value}\"'\n",
    "        return match.group(0)\n",
    "\n",
    "    pattern = re.compile(r'^(\\s*)expr:\\s+(.*)', re.MULTILINE)\n",
    "    return pattern.sub(replacer, yaml_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2ff0ecd-e8d0-419c-a4d4-c3f3e6b653b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refactor_value_quantity(documents):\n",
    "    updated_docs = []\n",
    "\n",
    "    for doc_index, doc in enumerate(documents):\n",
    "        cd = doc.get(\"class_derivations\", {})\n",
    "        for cls_name, cls_info in cd.items():\n",
    "            slot_derivs = cls_info.get(\"slot_derivations\", {})\n",
    "            populated_from = cls_info.get(\"populated_from\")\n",
    "\n",
    "            # Extract and clean slots to move into Quantity\n",
    "            quantity_subslots = {}\n",
    "            for slot in [\"value_decimal\", \"value_concept\", \"value_integer\", \"value_quantity.unit\"]:\n",
    "                # Support nested key for value_quantity.unit\n",
    "                key_in_slot_derivs = slot if slot in slot_derivs else slot.split(\".\")[-1]\n",
    "                entry = slot_derivs.pop(slot, None) or slot_derivs.pop(key_in_slot_derivs, None)\n",
    "                if entry:\n",
    "                    if isinstance(entry, dict):\n",
    "                        pf = entry.get(\"populated_from\")\n",
    "                        expr = entry.get(\"expr\")\n",
    "\n",
    "                        if pf and isinstance(pf, dict) and \"expr\" in pf:\n",
    "                            quantity_subslots[slot.split(\".\")[-1]] = {\"expr\": pf[\"expr\"]}\n",
    "                        elif expr:\n",
    "                            quantity_subslots[slot.split(\".\")[-1]] = {\"expr\": expr}\n",
    "                        elif pf is None:\n",
    "                            raise ValueError(f\"[Doc {doc_index}] `{slot}` has an empty `populated_from:` and no `expr:`\")\n",
    "                        elif isinstance(pf, str):\n",
    "                            quantity_subslots[slot.split(\".\")[-1]] = {\"populated_from\": pf}\n",
    "                        else:\n",
    "                            raise ValueError(f\"[Doc {doc_index}] Malformed `{slot}`: {entry}\")\n",
    "                    else:\n",
    "                        raise ValueError(f\"[Doc {doc_index}] Unexpected `{slot}` format: {entry}\")\n",
    "\n",
    "            # If any were found, create a nested Quantity class derivation\n",
    "            if quantity_subslots:\n",
    "                quantity_deriv = {\n",
    "                    \"class_derivations\": {\n",
    "                        \"Quantity\": {\n",
    "                            \"populated_from\": populated_from,\n",
    "                            \"slot_derivations\": quantity_subslots\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                slot_derivs[\"value_quantity\"] = {\n",
    "                    \"object_derivations\": [quantity_deriv]\n",
    "                }\n",
    "\n",
    "        updated_docs.append(doc)\n",
    "\n",
    "    return updated_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05cf4540-06ce-498f-a45b-3eb7e3e4ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_populated_from_with_pht(documents, phv_to_pht):\n",
    "    import re\n",
    "\n",
    "    def find_first_phv_in_slot(slot_derivations):\n",
    "        for slot_value in slot_derivations.values():\n",
    "            if isinstance(slot_value, dict):\n",
    "                pf = slot_value.get(\"populated_from\")\n",
    "                expr = slot_value.get(\"expr\")\n",
    "\n",
    "                if isinstance(pf, str) and pf.startswith(\"phv\"):\n",
    "                    return pf\n",
    "                if isinstance(expr, str):\n",
    "                    match = re.search(r\"(phv\\d{8})\", expr)\n",
    "                    if match:\n",
    "                        return match.group(1)\n",
    "        return None\n",
    "\n",
    "    def update_class_derivations(cls_derivations, doc_index, context=\"root\"):\n",
    "        for cls_name, cls_info in cls_derivations.items():\n",
    "            slot_derivs = cls_info.get(\"slot_derivations\", {})\n",
    "            pf = cls_info.get(\"populated_from\")\n",
    "\n",
    "            if pf == \"FHS\":\n",
    "                phv = find_first_phv_in_slot(slot_derivs)\n",
    "                if phv and phv in phv_to_pht:\n",
    "                    new_pf = phv_to_pht[phv]\n",
    "                    cls_info[\"populated_from\"] = new_pf\n",
    "                    # print(f\"✅ Updated {context}.{cls_name} populated_from: {phv} -> {new_pf}\")\n",
    "                else:\n",
    "                    print(f\"⚠️ Warning: No matching phv for {context}.{cls_name} in doc {doc_index}\")\n",
    "\n",
    "            # Recurse into nested object_derivations\n",
    "            for slot_name, slot_value in slot_derivs.items():\n",
    "                if isinstance(slot_value, dict) and \"object_derivations\" in slot_value:\n",
    "                    for obj in slot_value[\"object_derivations\"]:\n",
    "                        inner_cls_derivs = obj.get(\"class_derivations\")\n",
    "                        if inner_cls_derivs:\n",
    "                            update_class_derivations(inner_cls_derivs, doc_index, context=f\"{context}.{cls_name}.{slot_name}\")\n",
    "\n",
    "    for doc_index, doc in enumerate(documents):\n",
    "        top_cd = doc.get(\"class_derivations\", {})\n",
    "        update_class_derivations(top_cd, doc_index)\n",
    "\n",
    "    return documents\n",
    "\n",
    "def load_phv_to_pht_map(file_path):\n",
    "    with open(file_path) as f:\n",
    "        return dict(line.strip().split(\": \") for line in f if line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48f126a7-96ea-4206-aabb-8bc1363e78ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = Path(\"NHLBI-BDC-DMC-HV/priority_variables_transform/FHS/bdy_hgt.yaml\").read_text()\n",
    "quoted_fixed = quote_expr_values(raw)\n",
    "split_blocks = re.split(r'(?<=\\n)(?=^\\s*class_derivations:\\s*)', quoted_fixed, flags=re.MULTILINE)\n",
    "parsed_docs = [yaml.safe_load(doc) for doc in split_blocks]\n",
    "\n",
    "refactored_docs = refactor_value_quantity(parsed_docs)\n",
    "\n",
    "phv_to_pht = load_phv_to_pht_map(\"NHLBI-BDC-DMC-HV/priority_variables_transform/FHS/phv_to_pht.txt\")\n",
    "\n",
    "pht_replace_docs = update_populated_from_with_pht(refactored_docs, phv_to_pht)\n",
    "\n",
    "# Dump to YAML\n",
    "with open(\"NHLBI-BDC-DMC-HV/priority_variables_transform/FHS-ingest/\" + \"bdy_hgt\" + \".yaml\", \"w\") as f:\n",
    "    yaml.dump(pht_replace_docs, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "375c25d4-2729-4fba-a018-d933f47cbd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set base name\n",
    "spec_dir = \"NHLBI-BDC-DMC-HV/priority_variables_transform/FHS\"\n",
    "base = \"afib\"\n",
    "data_dir = \"output/FHS_v31_c1\"\n",
    "\n",
    "# Run the shell command to regenerate phv_to_pht.txt\n",
    "subprocess.run(\n",
    "    f\"\"\"for phv in $(grep -ho 'phv[0-9]\\\\{{8\\\\}}' {spec_dir}/{base}.yaml | sort -u); do \\\n",
    "    grep -l \"$phv\" {data_dir}/*.tsv | \\\n",
    "    sed -E \"s|.*/(pht[0-9]{{6,}}).tsv|$phv: \\\\1|\"; done > phv_to_pht.txt\"\"\",\n",
    "    shell=True, check=True,\n",
    ")\n",
    "\n",
    "# Load and process the YAML\n",
    "raw = Path(f\"NHLBI-BDC-DMC-HV/priority_variables_transform/FHS/{base}.yaml\").read_text()\n",
    "quoted_fixed = quote_expr_values(raw)\n",
    "split_blocks = re.split(r'(?<=\\n)(?=^\\s*class_derivations:\\s*)', quoted_fixed, flags=re.MULTILINE)\n",
    "parsed_docs = [yaml.safe_load(doc) for doc in split_blocks]\n",
    "\n",
    "refactored_docs = refactor_value_quantity(parsed_docs)\n",
    "\n",
    "phv_to_pht = load_phv_to_pht_map(\"NHLBI-BDC-DMC-HV/priority_variables_transform/FHS/phv_to_pht.txt\")\n",
    "\n",
    "pht_replace_docs = update_populated_from_with_pht(refactored_docs, phv_to_pht)\n",
    "\n",
    "# Dump to YAML\n",
    "with open(f\"NHLBI-BDC-DMC-HV/priority_variables_transform/FHS-ingest/{base}.yaml\", \"w\") as f:\n",
    "    yaml.dump(pht_replace_docs, f, sort_keys=False, allow_unicode=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1995fd78-b9a7-4760-ab4a-fe08e3499b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afib\n",
      "albumin_bld\n",
      "albumin_urine\n",
      "⏭️ Skipping alt_sgpt\n",
      "angina\n",
      "apnea_hypop_index\n",
      "ast_sgot\n",
      "asthma\n",
      "basophil_ncnc_bld\n",
      "⏭️ Skipping bdy_hgt\n",
      "⏭️ Skipping bdy_wgt\n",
      "bilirubin_con\n",
      "bilirubin_tot\n",
      "⏭️ Skipping bld_pressure\n",
      "bmi\n",
      "bnp\n",
      "bun\n",
      "cac_score\n",
      "cac_volume\n",
      "carotid_imt\n",
      "carotid_sten_left\n",
      "carotid_sten_right\n",
      "⏭️ Skipping cause_of_death\n",
      "cd40\n",
      "cesd_score\n",
      "chloride_bld\n",
      "vege_serving\n",
      "copd\n",
      "⏭️ Skipping creat_bld\n",
      "creat_urin\n",
      "crp\n",
      "cysc_bld\n",
      "d_dimer\n",
      "death_stat\n",
      "willeb_fac\n",
      "diabetes\n",
      "⏭️ Skipping edu_lvl\n",
      "eosinophil_ncnc_bld\n",
      "eselectin\n",
      "factor_7\n",
      "factor_8\n",
      "⏭️ Skipping fam_income\n",
      "fam_stroke\n",
      "⏭️ Skipping fast_gluc_bld\n",
      "fast_lipids\n",
      "ferritin\n",
      "fev1\n",
      "fibrin\n",
      "fruit_serving\n",
      "fvc\n",
      "⏭️ Skipping glucose_bld\n",
      "⏭️ Skipping hdl\n",
      "hemat\n",
      "hemo\n",
      "hemo_a1c\n",
      "⏭️ Skipping hip_circ\n",
      "⏭️ Skipping hist_cor_angio\n",
      "⏭️ Skipping hist_cor_bypg\n",
      "hist_cvd\n",
      "hist_hrtdis\n",
      "hist_hrtfail\n",
      "⏭️ Skipping hist_my_inf\n",
      "⏭️ Skipping hrtrt\n",
      "hypert_trt\n",
      "⏭️ Skipping hypertension\n",
      "icam\n",
      "⏭️ Skipping insulin_in_blood\n",
      "interleuk_10\n",
      "interleuk_1_beta\n",
      "interleuk_6\n",
      "lactate\n",
      "lactate_dh\n",
      "⏭️ Skipping ldl\n",
      "lvh_ekg\n",
      "mch\n",
      "mchc\n",
      "mcv\n",
      "mean_art_press\n",
      "mmp9\n",
      "monocyte_ncnc_bld\n",
      "mpo\n",
      "⏭️ Skipping nt_bnp\n",
      "obesity\n",
      "opg\n",
      "pad\n",
      "platelet_ct\n",
      "pmv\n",
      "pr_qrs_qt\n",
      "qrs_ekg\n",
      "qt_ekg\n",
      "rdbld_ct\n",
      "rdw\n",
      "sleep_duration_daily\n",
      "sodium_blood\n",
      "spo2\n",
      "tak_aceinhib\n",
      "tak_aldorecepblk\n",
      "tak_alphablk\n",
      "tak_angiorecepblk\n",
      "⏭️ Skipping tak_calchanblk\n",
      "tak_cenactag\n",
      "⏭️ Skipping tak_diuret\n",
      "tak_insulin\n",
      "tak_med_diab\n",
      "tak_nstat_med\n",
      "tak_orlhypoag\n",
      "tak_statin\n",
      "tak_vasodil\n",
      "⏭️ Skipping tot_chol_bld\n",
      "⏭️ Skipping triglyc_bld\n",
      "⏭️ Skipping troponin\n",
      "⏭️ Skipping valv_hrtdis\n",
      "⏭️ Skipping ven_thromb\n",
      "⏭️ Skipping waist_circ\n",
      "⏭️ Skipping whtbld_ct\n",
      "lympho_pct\n",
      "med_use\n",
      "⏭️ Skipping tak_betablk\n",
      "tnfa\n",
      "⏭️ Skipping cig_smok\n",
      "demography\n",
      "mcp1\n",
      "⏭️ Skipping stroke\n"
     ]
    }
   ],
   "source": [
    "spec_dir = Path(\"/sbgenomics/workspace/NHLBI-BDC-DMC-HV/priority_variables_transform/FHS\")\n",
    "data_dir = \"/sbgenomics/workspace/output/FHS_v31_c1\"\n",
    "output_dir = Path(\"/sbgenomics/workspace/NHLBI-BDC-DMC-HV/priority_variables_transform/FHS-ingest\")\n",
    "\n",
    "# Not complete: \n",
    "SKIP_BASES = {\"alt_sgpt\", \"bdy_hgt\", \"bdy_wgt\", \"bld_pressure\", \"cause_of_death\", \"cig_smoke\",\n",
    "              \"creat_bld\", \"edu_lvl\", \"fam_income\", \"fast_gluc_bld\", \"glucose_bld\", \"hdl\", \"hip_circ\",\n",
    "              \"hist_cor_angio\", \"hist_cor_bypg\", \"hist_my_inf\", \"hrtrt\", \"hypertension\", \"insulin_in_blood\",\n",
    "              \"ldl\", \"nt_bnp\", \"tak_calchanblk\", \"tak_diuret\", \"tot_chol_bld\", \"triglyc_bld\", \"troponin\", \n",
    "              \"valv_hrtdis\", \"ven_thromb\", \"waist_circ\", \"whtbld_ct\", \"tak_betablk\", \"cig_smok\", \"stroke\"\n",
    "             }\n",
    "start_at = \"\"\n",
    "\n",
    "for yaml_file in spec_dir.glob(\"*.yaml\"):\n",
    "    base = yaml_file.stem  # Strip .yaml\n",
    "    output_file = f\"{output_dir}/{base}.yaml\"\n",
    "\n",
    "    if base in SKIP_BASES or base < start_at:\n",
    "        print(f\"⏭️ Skipping {base}\")\n",
    "        continue\n",
    "\n",
    "    # if Path(output_file).exists():\n",
    "    #     print(f\"⏭️ Output exists, skipping {base}\")\n",
    "    #     continue\n",
    "    \n",
    "    print(base)\n",
    "\n",
    "    # Run the shell command to regenerate phv dict\n",
    "    result = subprocess.run(\n",
    "        f\"\"\"for phv in $(grep -ho 'phv[0-9]\\\\{{8\\\\}}' {spec_dir}/{base}.yaml | sort -u); do \\\n",
    "        grep -l \"$phv\" {data_dir}/*.tsv | \\\n",
    "        sed -E \"s|.*/(pht[0-9]{{6,}}).tsv|$phv: \\\\1|\"; done\"\"\",\n",
    "        shell=True, check=True, capture_output=True, text=True,\n",
    "    )\n",
    "    phv_to_pht = dict(line.split(\": \") for line in result.stdout.strip().splitlines())\n",
    "\n",
    "    # Load and process the YAML\n",
    "    raw = yaml_file.read_text()\n",
    "    quoted_fixed = quote_expr_values(raw)\n",
    "    split_blocks = re.split(r'(?<=\\n)(?=^\\s*class_derivations:\\s*)', quoted_fixed, flags=re.MULTILINE)\n",
    "    parsed_docs = [yaml.safe_load(doc) for doc in split_blocks]\n",
    "\n",
    "    refactored_docs = refactor_value_quantity(parsed_docs)\n",
    "\n",
    "    # phv_to_pht = load_phv_to_pht_map(\"NHLBI-BDC-DMC-HV/priority_variables_transform/FHS/phv_to_pht.txt\")\n",
    "\n",
    "    pht_replace_docs = update_populated_from_with_pht(refactored_docs, phv_to_pht)\n",
    "\n",
    "    # Dump to YAML\n",
    "    with open(output_file, \"w\") as f:\n",
    "        yaml.dump(pht_replace_docs, f, sort_keys=False, allow_unicode=True)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6f59373-e14f-48ab-9472-5e560e202d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Person - top level class\n",
    "person_yaml = yaml.safe_load(\"\"\"\n",
    "class_derivations:\n",
    "  Person:\n",
    "    populated_from: pht000009\n",
    "    slot_derivations:\n",
    "      species:\n",
    "        expr: \"'Homo Sapiens'\"\n",
    "      identity:\n",
    "        populated_from: dbGaP_Subject_ID\n",
    "\"\"\")\n",
    "\n",
    "# # Dump to YAML\n",
    "# with open(var_dir + \"person\" + \".yaml\", \"w\") as f:\n",
    "#     yaml.dump(person_yaml, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6956b1d2-bcc6-47f8-8b35-763c7074f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sv = SchemaView(\"/sbgenomics/workspace/output/Schema_FHS_v31_c1/schema-automator-data/Schema_FHS_v31_c1.yaml\")\n",
    "source_schema = source_sv.schema\n",
    "\n",
    "target_sv = SchemaView(\"NHLBI-BDC-DMC-HM/src/bdchm/schema/bdchm.yaml\")\n",
    "target_schema = target_sv.schema\n",
    "\n",
    "var_dir = \"NHLBI-BDC-DMC-HV/priority_variables_transform/FHS/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "876642b2-8b28-4e39-8b12-4ca7822cc0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'species': 'Homo Sapiens', 'identity': [16956]}\n",
      "Transformation Successful!\n"
     ]
    }
   ],
   "source": [
    "transform_spec = person_yaml\n",
    "\n",
    "data_loader = TsvLoader(\"/sbgenomics/workspace/output/FHS_v31_c1/pht000009.tsv\")\n",
    "data_rows = data_loader.iter_instances()\n",
    "\n",
    "first_row = next(data_rows)\n",
    "cur_row = first_row\n",
    "\n",
    "# Create ObjectTransformer and apply transformation\n",
    "transformer = ObjectTransformer(unrestricted_eval=True)\n",
    "transformer.source_schemaview = SchemaView(source_schema)\n",
    "transformer.target_schemaview = SchemaView(target_schema)\n",
    "transformer.create_transformer_specification(transform_spec)\n",
    "\n",
    "result = transformer.map_object(cur_row, source_type=\"pht000009\")\n",
    "\n",
    "print(result)\n",
    "print(\"Transformation Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce73026a-6662-4abe-bfbc-5c737024a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participant - top level class for study data\n",
    "participant_yaml = yaml.safe_load(\"\"\"\n",
    "class_derivations:\n",
    "  Participant:\n",
    "    populated_from: pht000009\n",
    "    slot_derivations:\n",
    "      # associated_participant: \n",
    "      #   populated_from: phv00007675\n",
    "      identity:\n",
    "        populated_from: dbGaP_Subject_ID\n",
    "      member_of_research_study:\n",
    "        expr: \"'FHS'\"\n",
    "\"\"\")\n",
    "\n",
    "# # Dump to YAML\n",
    "# with open(var_dir + \"participant\" + \".yaml\", \"w\") as f:\n",
    "#     yaml.dump(participant_yaml, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c43d7ea-4564-48c3-a2a6-3c837e0b14dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class_derivations': {'MeasurementObservation': {'populated_from': 'pht000009',\n",
       "    'slot_derivations': {'associated_participant': {'populated_from': 'phv00001036'},\n",
       "     'associated_visit': {'expr': \"'FHS ORIGINAL EXAM 4'\"},\n",
       "     'observation_type': {'expr': \"'OBA:VT0001253'\"},\n",
       "     'value_quantity': {'object_derivations': [{'class_derivations': {'Quantity': {'populated_from': 'pht000009',\n",
       "          'slot_derivations': {'value_decimal': {'expr': '{phv00000680} * 2.54'},\n",
       "           'unit': {'expr': \"'cm'\"}}}}}]}}}}},\n",
       " {'class_derivations': {'MeasurementObservation': {'populated_from': 'pht000009',\n",
       "    'slot_derivations': {'associated_participant': {'populated_from': 'phv00001036'},\n",
       "     'associated_visit': {'expr': \"'FHS ORIGINAL EXAM 1'\"},\n",
       "     'observation_type': {'expr': \"'OBA:VT0001253'\"},\n",
       "     'value_quantity': {'object_derivations': [{'class_derivations': {'Quantity': {'populated_from': 'pht000009',\n",
       "          'slot_derivations': {'value_decimal': {'expr': '{phv00000539} * 2.54'},\n",
       "           'unit': {'expr': \"'cm'\"}}}}}]}}}}},\n",
       " {'class_derivations': {'MeasurementObservation': {'populated_from': 'pht000009',\n",
       "    'slot_derivations': {'associated_participant': {'populated_from': 'phv00001036'},\n",
       "     'associated_visit': {'expr': \"'FHS ORIGINAL EXAM 5'\"},\n",
       "     'observation_type': {'expr': \"'OBA:VT0001253'\"},\n",
       "     'value_quantity': {'object_derivations': [{'class_derivations': {'Quantity': {'populated_from': 'pht000009',\n",
       "          'slot_derivations': {'value_decimal': {'expr': '{phv00000744} * 2.54'},\n",
       "           'unit': {'expr': \"'cm'\"}}}}}]}}}}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MeasurementObservation class derivations\n",
    "bdy_hgt = refactored_docs\n",
    "# bdy_hgt = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"bdy_hgt\" + \".yaml\")))\n",
    "# bdy_wgt = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"bdy_wgt\" + \".yaml\")))\n",
    "# bmi = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"bmi\" + \".yaml\")))\n",
    "# bp_diastolic = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"bp_diastolic\" + \".yaml\")))\n",
    "# bp_systolic = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"bp_systolic\" + \".yaml\")))\n",
    "# fev1 = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"fev1\" + \".yaml\")))\n",
    "# fev1_fvc = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"fev1_fvc\" + \".yaml\")))\n",
    "# fvc = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"fvc\" + \".yaml\")))\n",
    "# hrt_rt = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"hrt_rt\" + \".yaml\")))\n",
    "# spo2 = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"spo2\" + \".yaml\")))\n",
    "\n",
    "# Get the demography slot on Participants class\n",
    "participant_cls = participant_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Participant\", {})\n",
    "participant_exposures_slot = participant_cls.setdefault(\"slot_derivations\", {}).setdefault(\"exposures\", {})\n",
    "\n",
    "# Add the Demography object_derivation to the demography slot\n",
    "participant_exposures_slot.setdefault(\"object_derivations\", bdy_hgt)\n",
    "# participant_exposures_slot.setdefault(\"object_derivations\", [\n",
    "#     bdy_hgt,\n",
    "#     tak_betablk,\n",
    "#     tak_adrenergics,\n",
    "#     tak_cort_steroid_resp,\n",
    "#     tak_cort_steroid_oral,\n",
    "#     tak_anabolic_steroid,\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3d38cb8-ced7-46d3-8685-84d100e98a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'identity': [16956], 'member_of_research_study': 'FHS', 'exposures': [{'associated_participant': 1, 'associated_visit': 'FHS ORIGINAL EXAM 4', 'observation_type': 'OBA:VT0001253', 'value_quantity': {'value_decimal': 162.56, 'unit': 'cm'}}, {'associated_participant': 1, 'associated_visit': 'FHS ORIGINAL EXAM 1', 'observation_type': 'OBA:VT0001253', 'value_quantity': {'value_decimal': 162.56, 'unit': 'cm'}}, {'associated_participant': 1, 'associated_visit': 'FHS ORIGINAL EXAM 5', 'observation_type': 'OBA:VT0001253', 'value_quantity': {'value_decimal': 162.56, 'unit': 'cm'}}]}\n",
      "Transformation Successful!\n"
     ]
    }
   ],
   "source": [
    "transform_spec = participant_yaml\n",
    "\n",
    "input_data = cur_row\n",
    "\n",
    "# Create ObjectTransformer and apply transformation\n",
    "transformer = ObjectTransformer(unrestricted_eval=True)\n",
    "transformer.source_schemaview = SchemaView(source_schema)\n",
    "transformer.target_schemaview = SchemaView(target_schema)\n",
    "transformer.create_transformer_specification(transform_spec)\n",
    "\n",
    "result = transformer.map_object(input_data, source_type=\"pht000009\")\n",
    "\n",
    "# print(result)\n",
    "print(\"Transformation Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cd2ea45-fd3a-41cf-b3c7-b35599939f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class_derivations': {'Condition': {'populated_from': 'pht000030',\n",
       "    'slot_derivations': {'associated_participant': {'populated_from': 'phv00056635'},\n",
       "     'associated_visit': {'expr': \"'FHS OFFSPRING BASELINE'\"},\n",
       "     'condition_concept': {'expr': \"'HP:0001681'\"},\n",
       "     'condition_status': {'populated_from': 'phv00055298',\n",
       "      'value_mappings': {'0': 'ABSENT', '1': 'PRESENT', '8': 'UNKNOWN'}},\n",
       "     'condition_provenance': {'expr': \"'CLINICAL_DIAGNOSIS'\"},\n",
       "     'relationship_to_participant': {'expr': \"'ONESELF'\"}}}}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with one simple condition\n",
    "angina = yaml.safe_load(open(str(var_dir + \"angina\" + \".yaml\")))\n",
    "# print(yaml.dump(angina))\n",
    "\n",
    "# Get the conditions slot on Participants class\n",
    "participant_cls = participant_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Participant\", {})\n",
    "participant_exposures_slot = participant_cls.setdefault(\"slot_derivations\", {}).setdefault(\"conditions\", {})\n",
    "\n",
    "# Add the conditions object_derivation to the demography slot\n",
    "participant_exposures_slot.setdefault(\"object_derivations\", [\n",
    "    angina,\n",
    "    # asthma,\n",
    "    # copd,\n",
    "    # diabetes,\n",
    "    # hist_hrt_failure,\n",
    "    # hist_my_inf,\n",
    "    # hyperten,\n",
    "    # pad,\n",
    "    # slp_ap,\n",
    "    # stroke,\n",
    "    # stroke_isch_atk,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03bf4dbd-14f8-466e-828b-2d9ff79f24bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'identity': [16957], 'member_of_research_study': 'FHS', 'conditions': [{'associated_participant': None, 'associated_visit': 'FHS OFFSPRING BASELINE', 'condition_concept': 'HP:0001681', 'condition_status': None, 'condition_provenance': 'CLINICAL_DIAGNOSIS', 'relationship_to_participant': 'ONESELF'}]}\n",
      "Transformation Successful!\n"
     ]
    }
   ],
   "source": [
    "transform_spec = participant_yaml\n",
    "\n",
    "input_data = cur_row\n",
    "\n",
    "# Create ObjectTransformer and apply transformation\n",
    "transformer = ObjectTransformer(unrestricted_eval=True)\n",
    "transformer.source_schemaview = SchemaView(source_schema)\n",
    "transformer.target_schemaview = SchemaView(target_schema)\n",
    "transformer.create_transformer_specification(transform_spec)\n",
    "\n",
    "result = transformer.map_object(input_data, source_type=\"pht000030\")\n",
    "\n",
    "print(result)\n",
    "print(\"Transformation Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de820310-8052-4865-bee4-4c48b647f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_spec = refactored_docs\n",
    "\n",
    "\n",
    "data_loader = TsvLoader(\"/sbgenomics/workspace/output/FHS_v31_c1/pht000009.tsv\")\n",
    "data_rows = data_loader.iter_instances()\n",
    "\n",
    "first_row = next(data_rows)\n",
    "cur_row = first_row\n",
    "\n",
    "input_data = cur_row\n",
    "\n",
    "# Create ObjectTransformer and apply transformation\n",
    "transformer = ObjectTransformer(unrestricted_eval=True)\n",
    "transformer.source_schemaview = SchemaView(source_schema)\n",
    "transformer.target_schemaview = SchemaView(target_schema)\n",
    "transformer.create_transformer_specification(transform_spec)\n",
    "\n",
    "result = transformer.map_object(input_data, source_type=\"pht000009\")\n",
    "\n",
    "print(result)\n",
    "print(\"Transformation Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186c7e83-ac94-43fb-872d-9fa7fa3b366c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c44f9e6-2a70-495f-bc23-92fcccc10ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn sequential class_derivations (malformed yaml) into list of class derivations.\n",
    "\n",
    "# Function to fix unquoted expr: text (malformed yaml)\n",
    "def quote_expr_values(yaml_text):\n",
    "    def replacer(match):\n",
    "        indent = match.group(1)\n",
    "        value = match.group(2).strip()\n",
    "\n",
    "        # Don't quote if already quoted OR looks like a quoted literal\n",
    "        if value.startswith('\"') or value.startswith(\"'\"):\n",
    "            return match.group(0)\n",
    "\n",
    "        # Don't quote if it's a simple scalar (e.g., a single variable)\n",
    "        if re.match(r'^[\\w{}\\s\\*\\+\\-/().]+$', value):\n",
    "            return f'{indent}expr: \"{value}\"'\n",
    "\n",
    "        # Otherwise, leave it as-is\n",
    "        return match.group(0)\n",
    "\n",
    "    pattern = re.compile(r'^(\\s*)expr:\\s+(.*)', re.MULTILINE)\n",
    "    return pattern.sub(replacer, yaml_text)\n",
    "\n",
    "# Read the raw YAML as text\n",
    "raw = Path(\"NHLBI-BDC-DMC-HV/priority_variables_transform/FHS/bdy_hgt_test.yaml\").read_text()\n",
    "# print(raw)\n",
    "\n",
    "quoted_fixed = quote_expr_values(raw)\n",
    "# Split while *keeping* 'class_derivations:' in each result, skip first line\n",
    "split_blocks = re.split(r'(?<=\\n)(?=^\\s*class_derivations:\\s*)', quoted_fixed, flags=re.MULTILINE)\n",
    "# print(split_blocks)\n",
    "\n",
    "# print(split_blocks)\n",
    "parsed_docs = [yaml.safe_load(doc) for doc in split_blocks]\n",
    "print(yaml.dump(parsed_docs))\n",
    "\n",
    "\n",
    "raw2 = Path(\"NHLBI-BDC-DMC-HV/priority_variables_transform/FHS/bdy_hgt_test2.yaml\").read_text()\n",
    "# print(raw2)\n",
    "\n",
    "# Split while *keeping* 'class_derivations:' in each result, skip first line\n",
    "split_blocks2 = re.split(r'(?<=\\n)(?=^\\s*class_derivations:\\s*)', raw2, flags=re.MULTILINE)\n",
    "# print(split_blocks2)\n",
    "print(split_blocks == split_blocks2)\n",
    "# quoted_fixed2 = quote_expr_values(raw2)\n",
    "# print(quoted_fixed2)\n",
    "parsed_docs2 = [yaml.safe_load(doc) for doc in split_blocks2]\n",
    "# print(yaml.dump(parsed_docs2))\n",
    "\n",
    "# parsed_docs = [yaml.safe_load(doc) for doc in quoted_fixed]\n",
    "\n",
    "# Use these if we can't guarantee the first class_derivation is first line of file.\n",
    "# # Split while *keeping* 'class_derivations:' in each result\n",
    "# split_blocks = re.split(r'(?=^\\s*class_derivations:\\s*)', raw, flags=re.MULTILINE)\n",
    "# # First block is likely empty or comments/header — skip it\n",
    "# blocks = [b for b in split_blocks[1:]]\n",
    "# parsed_docs = [yaml.safe_load(doc) for doc in blocks]\n",
    "\n",
    "# print(yaml.dump(quoted_fixed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdb0f83-db6c-42ca-a11f-66a01b5203f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn sequential class_derivations (malformed yaml) into list of class derivations.\n",
    "\n",
    "# Read the raw YAML as text\n",
    "raw = Path(\"NHLBI-BDC-DMC-HV/priority_variables_transform/FHS/apnea_hypop_index.yaml\").read_text()\n",
    "print(raw)\n",
    "\n",
    "# Split while *keeping* 'class_derivations:' in each result, skip first line\n",
    "split_blocks = re.split(r'(?<=\\n)(?=^\\s*class_derivations:\\s*)', raw, flags=re.MULTILINE)\n",
    "parsed_docs = [yaml.safe_load(doc) for doc in split_blocks]\n",
    "\n",
    "# Use these if we can't guarantee the first class_derivation is first line of file.\n",
    "# # Split while *keeping* 'class_derivations:' in each result\n",
    "# split_blocks = re.split(r'(?=^\\s*class_derivations:\\s*)', raw, flags=re.MULTILINE)\n",
    "# # First block is likely empty or comments/header — skip it\n",
    "# blocks = [b for b in split_blocks[1:]]\n",
    "# parsed_docs = [yaml.safe_load(doc) for doc in blocks]\n",
    "\n",
    "print(yaml.dump(parsed_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50907a8-faba-41aa-866d-4d793ad177b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "class LazySubjectDict(dict):\n",
    "    \"\"\"\n",
    "    Lazily loads per-pht data for a single subject on demand.\n",
    "    \"\"\"\n",
    "    def __init__(self, subject_id, data_dir):\n",
    "        super().__init__()\n",
    "        self.subject_id = subject_id\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self._cache = {}\n",
    "\n",
    "    def __getitem__(self, pht_id):\n",
    "        if pht_id in self._cache:\n",
    "            return self._cache[pht_id]\n",
    "\n",
    "        file_path = self.data_dir / f\"{pht_id}.tsv\"\n",
    "        if not file_path.exists():\n",
    "            raise KeyError(f\"No such file: {file_path}\")\n",
    "\n",
    "        with open(file_path, newline='') as f:\n",
    "            reader = csv.DictReader(f, delimiter=\"\\t\")\n",
    "            for row in reader:\n",
    "                if row.get(\"dbGaP_Subject_ID\") == self.subject_id:\n",
    "                    self._cache[pht_id] = row\n",
    "                    return row\n",
    "\n",
    "        raise KeyError(f\"Subject {self.subject_id} not found in {pht_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef9c58-9bce-420c-9248-7c0f9a64ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sv = SchemaView(\"/sbgenomics/workspace/output/Schema_FHS_v31_c1/schema-automator-data/Schema_FHS_v31_c1.yaml\")\n",
    "source_schema = source_sv.schema\n",
    "\n",
    "target_sv = SchemaView(\"NHLBI-BDC-DMC-HM/src/bdchm/schema/bdchm.yaml\")\n",
    "target_schema = target_sv.schema\n",
    "\n",
    "data_loader = TsvLoader(\"/sbgenomics/workspace/output/FHS_v31_c1/pht000030.tsv\")\n",
    "data_rows = data_loader.iter_instances()\n",
    "\n",
    "first_row = next(data_rows)\n",
    "cur_row = first_row\n",
    "\n",
    "var_dir = \"NHLBI-BDC-DMC-HV/priority_variables_transform/FHS/\"\n",
    "print(cur_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd0c51-db7e-455b-8a76-0e650078f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Person - top level class\n",
    "person_yaml = yaml.safe_load(\"\"\"\n",
    "class_derivations:\n",
    "  Person:\n",
    "    populated_from: pht000030\n",
    "    slot_derivations:\n",
    "      species:\n",
    "        expr: \"'Homo Sapiens'\"\n",
    "      identity:\n",
    "        populated_from: dbGaP_Subject_ID\n",
    "\"\"\")\n",
    "\n",
    "# # Dump to YAML\n",
    "# with open(var_dir + \"person\" + \".yaml\", \"w\") as f:\n",
    "#     yaml.dump(person_yaml, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d2f07c-b3ff-4c79-afc4-cb4c14d566c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participant - top level class for study data\n",
    "participant_yaml = yaml.safe_load(\"\"\"\n",
    "class_derivations:\n",
    "  Participant:\n",
    "    populated_from: pht000030\n",
    "    slot_derivations:\n",
    "      # associated_participant: \n",
    "      #   populated_from: phv00007675\n",
    "      identity:\n",
    "        populated_from: dbGaP_Subject_ID\n",
    "      member_of_research_study:\n",
    "        expr: \"'FHS'\"\n",
    "\"\"\")\n",
    "\n",
    "# # Dump to YAML\n",
    "# with open(var_dir + \"participant\" + \".yaml\", \"w\") as f:\n",
    "#     yaml.dump(participant_yaml, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8930fcd2-e946-456b-b50f-4daa8af5ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_spec = participant_yaml\n",
    "\n",
    "input_data = cur_row\n",
    "\n",
    "# Create ObjectTransformer and apply transformation\n",
    "transformer = ObjectTransformer(unrestricted_eval=True)\n",
    "transformer.source_schemaview = SchemaView(source_schema)\n",
    "transformer.target_schemaview = SchemaView(target_schema)\n",
    "transformer.create_transformer_specification(transform_spec)\n",
    "\n",
    "result = transformer.map_object(input_data, source_type=\"pht000030\")\n",
    "\n",
    "print(result)\n",
    "print(\"Transformation Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875a70eb-fe22-4b65-b53e-f250ff391f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the participants slot\n",
    "person_class = person_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Person\", {})\n",
    "person_participants_slot = person_class.setdefault(\"slot_derivations\", {}).setdefault(\"participants\", {})\n",
    "\n",
    "# Add the Participant object_derivation to the participants slot\n",
    "person_participants_slot.setdefault(\"object_derivations\", [ participant_yaml ])\n",
    "\n",
    "# print(yaml.dump(person_yaml, sort_keys=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209e7ddc-617e-4eee-b678-61ec490c1b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_spec = person_yaml\n",
    "\n",
    "input_data = cur_row\n",
    "\n",
    "# Create ObjectTransformer and apply transformation\n",
    "transformer = ObjectTransformer(unrestricted_eval=True)\n",
    "transformer.source_schemaview = SchemaView(source_schema)\n",
    "transformer.target_schemaview = SchemaView(target_schema)\n",
    "transformer.create_transformer_specification(transform_spec)\n",
    "\n",
    "result = transformer.map_object(input_data, source_type=\"pht000030\")\n",
    "\n",
    "print(result)\n",
    "print(\"Transformation Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5cb63d-1d40-450b-b4b8-d9454a45a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with one simple condition\n",
    "angina = yaml.safe_load(open(str(var_dir + \"angina\" + \".yaml\")))\n",
    "# print(yaml.dump(angina))\n",
    "\n",
    "# Get the conditions slot on Participants class\n",
    "participant_cls = participant_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Participant\", {})\n",
    "participant_exposures_slot = participant_cls.setdefault(\"slot_derivations\", {}).setdefault(\"conditions\", {})\n",
    "\n",
    "# Add the conditions object_derivation to the demography slot\n",
    "participant_exposures_slot.setdefault(\"object_derivations\", [\n",
    "    angina,\n",
    "    # asthma,\n",
    "    # copd,\n",
    "    # diabetes,\n",
    "    # hist_hrt_failure,\n",
    "    # hist_my_inf,\n",
    "    # hyperten,\n",
    "    # pad,\n",
    "    # slp_ap,\n",
    "    # stroke,\n",
    "    # stroke_isch_atk,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0a51fe-3ba9-474b-aae5-6d903e1b18d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yaml.dump(person_yaml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a1c2fc-e2a1-47cd-83a3-e6d257aff0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_spec = person_yaml\n",
    "\n",
    "data_loader = TsvLoader(\"/sbgenomics/workspace/output/FHS_v31_c1/pht000030.tsv\")\n",
    "data_rows = data_loader.iter_instances()\n",
    "\n",
    "first_row = next(data_rows)\n",
    "cur_row = first_row\n",
    "\n",
    "other_data_loader = TsvLoader(\"/sbgenomics/workspace/output/FHS_v31_c1/pht000395.tsv\")\n",
    "other_data_rows = other_data_loader.iter_instances()\n",
    "\n",
    "other_first_row = next(other_data_rows)\n",
    "other_cur_row = other_first_row\n",
    "\n",
    "input_data = {\n",
    "    \"pht000030\": cur_row,\n",
    "    \"pht000395\": other_cur_row\n",
    "}\n",
    "\n",
    "\n",
    "# Create ObjectTransformer and apply transformation\n",
    "transformer = ObjectTransformer(unrestricted_eval=True)\n",
    "transformer.source_schemaview = SchemaView(source_schema)\n",
    "transformer.target_schemaview = SchemaView(target_schema)\n",
    "transformer.create_transformer_specification(transform_spec)\n",
    "\n",
    "result = transformer.map_object(input_data, source_type=\"FHS\")\n",
    "\n",
    "print(result)\n",
    "print(\"Transformation Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d01721d-7268-4c24-9231-2707f85ba6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Condition class derivations\n",
    "angina = yaml.safe_load(open(str(var_dir + \"condition/\" + \"angina\" + \".yaml\")))\n",
    "asthma = yaml.safe_load(open(str(var_dir + \"condition/\" + \"asthma\" + \".yaml\")))\n",
    "copd = yaml.safe_load(open(str(var_dir + \"condition/\" + \"copd\" + \".yaml\")))\n",
    "diabetes = yaml.safe_load(open(str(var_dir + \"condition/\" + \"diabetes\" + \".yaml\")))\n",
    "hist_hrt_failure = yaml.safe_load(open(str(var_dir + \"condition/\" + \"hist_hrt_failure\" + \".yaml\")))\n",
    "hist_my_inf = yaml.safe_load(open(str(var_dir + \"condition/\" + \"hist_my_inf\" + \".yaml\")))\n",
    "hyperten = yaml.safe_load(open(str(var_dir + \"condition/\" + \"hyperten\" + \".yaml\")))\n",
    "pad = yaml.safe_load(open(str(var_dir + \"condition/\" + \"pad\" + \".yaml\")))\n",
    "slp_ap = yaml.safe_load(open(str(var_dir + \"condition/\" + \"slp_ap\" + \".yaml\")))\n",
    "stroke = yaml.safe_load(open(str(var_dir + \"condition/\" + \"stroke\" + \".yaml\")))\n",
    "stroke_isch_atk = yaml.safe_load(open(str(var_dir + \"condition/\" + \"stroke_isch_atk\" + \".yaml\")))\n",
    "\n",
    "# Get the conditions slot on Participants class\n",
    "participant_cls = participant_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Participant\", {})\n",
    "participant_exposures_slot = participant_cls.setdefault(\"slot_derivations\", {}).setdefault(\"conditions\", {})\n",
    "\n",
    "# Add the conditions object_derivation to the demography slot\n",
    "participant_exposures_slot.setdefault(\"object_derivations\", [\n",
    "    angina,\n",
    "    asthma,\n",
    "    copd,\n",
    "    diabetes,\n",
    "    hist_hrt_failure,\n",
    "    hist_my_inf,\n",
    "    hyperten,\n",
    "    pad,\n",
    "    slp_ap,\n",
    "    stroke,\n",
    "    stroke_isch_atk,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7015ab-d611-4c13-8cbf-dc2822def350",
   "metadata": {},
   "outputs": [],
   "source": [
    "demography_yaml = yaml.safe_load(\"\"\"\n",
    "class_derivations:\n",
    "  Demography:\n",
    "    populated_from: COPDGene\n",
    "    slot_derivations:\n",
    "      associated_participant:\n",
    "        populated_from: phv00159568\n",
    "      sex:\n",
    "        populated_from: phv00159571\n",
    "        value_mappings:\n",
    "          '1': OMOP:8507  # MALE\n",
    "          '2': OMOP:8532  # FEMALE\n",
    "      ethnicity:\n",
    "        populated_from: phv00159573\n",
    "        value_mappings:\n",
    "          '1': HISPANIC_OR_LATINO\n",
    "          '2': NOT_HISPANIC_OR_LATINO\n",
    "      race:\n",
    "        populated_from: phv00159572\n",
    "        value_mappings:\n",
    "          '1': OMOP:8527\n",
    "          '2': OMOP:8516\n",
    "          '3': OMOP:8515\n",
    "          '4': OMOP:8557\n",
    "          '5': OMOP:8657\n",
    "          '6': OMOP:45880900\n",
    "          '7': OMOP:8552\n",
    "\"\"\")\n",
    "\n",
    "# Dump to YAML\n",
    "with open(var_dir + \"demography\" + \".yaml\", \"w\") as f:\n",
    "    yaml.dump(demography_yaml, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0d3105-77d7-433b-a16a-5ddb36660e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the demography slot on Participants class\n",
    "participant_cls = participant_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Participant\", {})\n",
    "participant_demography_slot = participant_cls.setdefault(\"slot_derivations\", {}).setdefault(\"demography\", {})\n",
    "\n",
    "# Add the Demography object_derivation to the demography slot\n",
    "participant_demography_slot.setdefault(\"object_derivations\", [ demography_yaml ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed5ad67-f675-4164-ae89-ec6841e2d18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DrugExposure class derivations\n",
    "tak_betablk_resp = yaml.safe_load(open(str(var_dir + \"exposure/\" + \"tak_betablk_resp\" + \".yaml\")))\n",
    "tak_betablk = yaml.safe_load(open(str(var_dir + \"exposure/\" + \"tak_betablk\" + \".yaml\")))\n",
    "tak_adrenergics = yaml.safe_load(open(str(var_dir + \"exposure/\" + \"tak_adrenergics\" + \".yaml\")))\n",
    "tak_cort_steroid_resp = yaml.safe_load(open(str(var_dir + \"exposure/\" + \"tak_cort_steroid_resp\" + \".yaml\")))\n",
    "tak_cort_steroid_oral = yaml.safe_load(open(str(var_dir + \"exposure/\" + \"tak_cort_steroid_oral\" + \".yaml\")))\n",
    "tak_anabolic_steroid = yaml.safe_load(open(str(var_dir + \"exposure/\" + \"tak_anabolic_steroid\" + \".yaml\")))\n",
    "\n",
    "# Get the demography slot on Participants class\n",
    "participant_cls = participant_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Participant\", {})\n",
    "participant_exposures_slot = participant_cls.setdefault(\"slot_derivations\", {}).setdefault(\"exposures\", {})\n",
    "\n",
    "# Add the Demography object_derivation to the demography slot\n",
    "participant_exposures_slot.setdefault(\"object_derivations\", [\n",
    "    tak_betablk_resp,\n",
    "    tak_betablk,\n",
    "    tak_adrenergics,\n",
    "    tak_cort_steroid_resp,\n",
    "    tak_cort_steroid_oral,\n",
    "    tak_anabolic_steroid,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e7c770-d698-4a11-aaa4-0b371e8ea8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MeasurementObservation class derivations\n",
    "bdy_hgt = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"bdy_hgt\" + \".yaml\")))\n",
    "bdy_wgt = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"bdy_wgt\" + \".yaml\")))\n",
    "bmi = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"bmi\" + \".yaml\")))\n",
    "bp_diastolic = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"bp_diastolic\" + \".yaml\")))\n",
    "bp_systolic = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"bp_systolic\" + \".yaml\")))\n",
    "fev1 = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"fev1\" + \".yaml\")))\n",
    "fev1_fvc = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"fev1_fvc\" + \".yaml\")))\n",
    "fvc = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"fvc\" + \".yaml\")))\n",
    "hrt_rt = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"hrt_rt\" + \".yaml\")))\n",
    "spo2 = yaml.safe_load(open(str(var_dir + \"measurement_observation/\" + \"spo2\" + \".yaml\")))\n",
    "\n",
    "# Get the demography slot on Participants class\n",
    "participant_cls = participant_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Participant\", {})\n",
    "participant_exposures_slot = participant_cls.setdefault(\"slot_derivations\", {}).setdefault(\"exposures\", {})\n",
    "\n",
    "# Add the Demography object_derivation to the demography slot\n",
    "participant_exposures_slot.setdefault(\"object_derivations\", [\n",
    "    bdy_hgt,\n",
    "    tak_betablk,\n",
    "    tak_adrenergics,\n",
    "    tak_cort_steroid_resp,\n",
    "    tak_cort_steroid_oral,\n",
    "    tak_anabolic_steroid,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dd1d49-f23d-4992-a0bd-f93241a510b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_yaml = yaml.safe_load(\"\"\"\n",
    "class_derivations:\n",
    "  Observation:\n",
    "    populated_from: COPDGene\n",
    "    slot_derivations:\n",
    "      associated_participant:\n",
    "        populated_from: phv00159568\n",
    "      observation_type:\n",
    "        expr: \"'OMOP:4282779'\"  # Cigarette smoking status\n",
    "      value_enum:\n",
    "        expr: \"'OMOP:40766945' if {phv00159749} == 1 else 'OMOP:45883458' if {phv00159747} == 1 else 'OMOP:45883537'\"\n",
    "\"\"\")\n",
    "\n",
    "# Dump to YAML\n",
    "with open(var_dir + \"observation\" + \".yaml\", \"w\") as f:\n",
    "    yaml.dump(observation_yaml, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ae05d-a027-447a-9e3c-216ed11e308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the observations slot on Participants class\n",
    "participant_cls = participant_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Participant\", {})\n",
    "participant_observations_slot = participant_cls.setdefault(\"slot_derivations\", {}).setdefault(\"observations\", {})\n",
    "\n",
    "# Add the Demography object_derivation to the demography slot\n",
    "participant_observations_slot.setdefault(\"object_derivations\", [ observation_yaml ])\n",
    "\n",
    "# print(yaml.dump(person_yaml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3705b06-a868-411d-91fe-273c2590a378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_cor_angio\n",
    "hist_cor_angio = yaml.safe_load(\"\"\"\n",
    "class_derivations:\n",
    "  Procedure:\n",
    "    populated_from: COPDGene\n",
    "    slot_derivations:\n",
    "      associated_participant:\n",
    "        populated_from: phv00159568\n",
    "      procedure_concept:\n",
    "        expr: \"'OMOP:4184832'\"  # Coronary angioplasty\n",
    "      procedure_status:\n",
    "        populated_from: phv00159632\n",
    "        value_mappings:\n",
    "          '0': ABSENT\n",
    "          '1': PRESENT\n",
    "\"\"\")\n",
    "\n",
    "# Dump to YAML\n",
    "with open(var_dir + \"procedure/\" + \"hist_cor_angio\" + \".yaml\", \"w\") as f:\n",
    "    yaml.dump(hist_cor_angio, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f881446b-f8a6-4948-a740-8f4c32f6052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_spec = hist_cor_angio\n",
    "\n",
    "input_data = cur_row\n",
    "\n",
    "# Create ObjectTransformer and apply transformation\n",
    "transformer = ObjectTransformer(unrestricted_eval=True)\n",
    "transformer.source_schemaview = SchemaView(source_schema)\n",
    "transformer.target_schemaview = SchemaView(target_schema)\n",
    "transformer.create_transformer_specification(transform_spec)\n",
    "\n",
    "result = transformer.map_object(input_data, source_type=\"COPDGene\")\n",
    "\n",
    "print(result)\n",
    "print(\"Transformation Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabe767f-d4c7-4c5a-8a24-31b846b744b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_cor_bypg\n",
    "hist_cor_bypg = yaml.safe_load(\"\"\"\n",
    "class_derivations:\n",
    "  Procedure:\n",
    "    populated_from: COPDGene\n",
    "    slot_derivations:\n",
    "      associated_participant:\n",
    "        populated_from: phv00159568\n",
    "      procedure_concept:\n",
    "        expr: \"'OMOP:4336464'\"  #coronary bypass graft\n",
    "      procedure_status:\n",
    "        populated_from: phv00159631\n",
    "        value_mappings:\n",
    "          '0': ABSENT\n",
    "          '1': PRESENT\n",
    "\"\"\")\n",
    "\n",
    "# Dump to YAML\n",
    "with open(var_dir + \"procedure/\" + \"hist_cor_bypg\" + \".yaml\", \"w\") as f:\n",
    "    yaml.dump(hist_cor_bypg, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05f167b-0aa3-4838-93fd-d7c1647f8d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the observations slot on Participants class\n",
    "participant_cls = participant_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Participant\", {})\n",
    "participant_procedures_slot = participant_cls.setdefault(\"slot_derivations\", {}).setdefault(\"procedures\", {})\n",
    "\n",
    "# Add the Demography object_derivation to the demography slot\n",
    "participant_procedures_slot.setdefault(\"object_derivations\", [ hist_cor_angio, hist_cor_bypg ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f40868-b270-4ceb-95d3-69e8d998d950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edu_lvl\n",
    "edu_lvl = yaml.safe_load(\"\"\"\n",
    "class_derivations:\n",
    "  SdohObservation:\n",
    "    populated_from: COPDGene\n",
    "    slot_derivations:\n",
    "      associated_participant:\n",
    "        populated_from: phv00159568\n",
    "      category:\n",
    "        expr: \"'EDUCATIONAL_ATTAINMENT'\"\n",
    "      value_enum:\n",
    "        populated_from: phv00159773\n",
    "        value_mappings:\n",
    "          '1': 8TH_GRADE_OR_LESS\n",
    "          '2': HIGH_SCHOOL_NO_DIPLOMA\n",
    "          '3': HIGH_SCHOOL_GRADUATE_GED\n",
    "          '4': SOME_COLLEGE_OR_TECH_NO_DEGREE\n",
    "          '5': COLLEGE_OR_TECH_WITH_DEGREE\n",
    "          '6': MASTERS_OR_DOCTORAL_DEGREE\n",
    "\"\"\")\n",
    "\n",
    "# Dump to YAML\n",
    "with open(var_dir + \"sdoh_observation/\" + \"edu_lvl\" + \".yaml\", \"w\") as f:\n",
    "    yaml.dump(edu_lvl, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee7fba1-14a5-4250-8a7f-fe8fb5859d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the observations slot on Participants class\n",
    "participant_cls = participant_yaml.setdefault(\"class_derivations\", {}).setdefault(\"Participant\", {})\n",
    "participant_sdoh_observations_slot = participant_cls.setdefault(\"slot_derivations\", {}).setdefault(\"sdoh_observations\", {})\n",
    "\n",
    "# Add the Demography object_derivation to the demography slot\n",
    "participant_sdoh_observations_slot.setdefault(\"object_derivations\", [ edu_lvl ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6070261a-440a-40ec-ad40-143c4cf59208",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_spec = person_yaml\n",
    "\n",
    "input_data = cur_row\n",
    "\n",
    "# Create ObjectTransformer and apply transformation\n",
    "transformer = ObjectTransformer(unrestricted_eval=True)\n",
    "transformer.source_schemaview = SchemaView(source_schema)\n",
    "transformer.target_schemaview = SchemaView(target_schema)\n",
    "transformer.create_transformer_specification(transform_spec)\n",
    "\n",
    "# Transform all rows\n",
    "output_data = []\n",
    "for row in data_rows:\n",
    "    result = transformer.map_object(row, source_type=\"COPDGene\")\n",
    "    if result:  # Avoid None or empty dicts\n",
    "        output_data.append(result)\n",
    "\n",
    "# Final wrapped structure (key should match the collection slot, or be schema-compatible)\n",
    "wrapped_output = {\n",
    "    \"persons\": output_data\n",
    "}\n",
    "\n",
    "# Dump to YAML\n",
    "with open(\"transformed_person_data_DS_CS.yaml\", \"w\") as f:\n",
    "    yaml.dump(wrapped_output, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "print(\"Transformation Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2751e283-9235-4423-b15e-d1922c612dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump final Person class to YAML\n",
    "with open(var_dir + \"person\" + \".yaml\", \"w\") as f:\n",
    "    yaml.dump(person_yaml, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5851b15-1e24-46cb-b95e-b7d50f656c44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dm-bip)",
   "language": "python",
   "name": "dm-bip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
