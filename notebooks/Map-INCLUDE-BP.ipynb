{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ede8ec5-3b57-4162-a30a-2ff8f1918110",
   "metadata": {},
   "source": [
    "# Map-INCLUDE Brain Power\n",
    "\n",
    "This notebook is to map the Brain Power study data to the INCLUDE LinkML model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf6739dc-7468-44b2-b00c-3ca089958005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "from linkml.validator.loaders import TsvLoader\n",
    "from linkml_runtime import SchemaView\n",
    "from linkml_map.transformer.object_transformer import ObjectTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d3790e2-4b96-4fa4-a347-8f7aa2371b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, base_path):\n",
    "        self.base_path = base_path\n",
    "\n",
    "    def __getitem__(self, pht_id):\n",
    "        file_path = os.path.join(self.base_path, f\"{entity}.tsv\")\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"No TSV file found for {entity} at {file_path}\")\n",
    "        return TsvLoader(os.path.join(self.base_path, f\"{entity}.tsv\")).iter_instances()\n",
    "\n",
    "    def __contains__(self, pht_id):\n",
    "        return os.path.exists(os.path.join(self.base_path, f\"{entity}.tsv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6af9497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c57ca815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_spec_transform(tsv_file, spec_file, source_schema, target_schema, target_class=\"Participant\"):\n",
    "    # Load your mapping spec\n",
    "    with open(spec_file) as f:\n",
    "        spec = yaml.safe_load(f)    \n",
    "    \n",
    "    # Load your TSV data\n",
    "    # TODO: Consider removing use of pandas and use TSVLoader from LinkML\n",
    "    # data = pd.read_csv(tsv_file, sep=\"\\t\").to_dict(orient=\"records\")\n",
    "    df = pd.read_csv(tsv_file, sep=\"\\t\")\n",
    "    df = df.fillna('')\n",
    "    data = df.to_dict(orient=\"records\")\n",
    "\n",
    "    # Another option to fix value_mappings - Set up the transformer once\n",
    "    transformer = ObjectTransformer(unrestricted_eval=True)\n",
    "    transformer.source_schemaview = SchemaView(source_schema)\n",
    "    transformer.target_schemaview = SchemaView(target_schema)\n",
    "\n",
    "    results = []\n",
    "    for block in spec:\n",
    "        if 'class_derivations' in block and target_class in block['class_derivations']:\n",
    "            class_spec = block['class_derivations'][target_class]\n",
    "            # Load this class mapping spec\n",
    "            transformer.create_transformer_specification(block)\n",
    "            for row in data:\n",
    "                mapped = transformer.map_object(row, source_type=class_spec[\"populated_from\"])\n",
    "                results.append(mapped)\n",
    "            break  # Only process the first matching block\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "results = list(single_spec_transform(\n",
    "    tsv_file=\"../data/BrainPower-STUDY/raw_data/TSV_Transformed/demographics_with_age_timepoints.tsv\",\n",
    "    # tsv_file=\"../data/BrainPower-STUDY/raw_data/TSV_Transformed/healthconditions_all_cols.tsv\", # Use with Condition as target class\n",
    "    spec_file=\"../data/BrainPower-STUDY/model_transformation/brain_power_transformation_PARTICIPANT-ONLY.yaml\",\n",
    "    # spec_file=\"../data/BrainPower-STUDY/model_transformation/brain_power_transformation_CONDITION-ONLY.yaml\", # Use with Condition as target class\n",
    "    source_schema=\"../data/BrainPower-STUDY/study_specific_model/BrainPower_INCLUDE_SCHEMA_v4.yaml\",\n",
    "    target_schema=\"../data/BrainPower-STUDY/include_schema/include_schema.yaml\",\n",
    "    target_class=\"Participant\"\n",
    "    # target_class=\"Condition\"\n",
    "))\n",
    "\n",
    "# FOR target_class=\"Participant\"\n",
    "with open(\"BP-demographics_transformed_FINAL.yaml\", \"w\") as f:\n",
    "    yaml.safe_dump(results, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "\n",
    "# # FOR target_class=\"Condition\"\n",
    "# with open(\"BP-conditions_transformed_FINAL.yaml\", \"w\") as f:\n",
    "#     yaml.safe_dump(results, f, sort_keys=False, allow_unicode=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1226eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a3f43e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dm-bip)",
   "language": "python",
   "name": "dm-bip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
